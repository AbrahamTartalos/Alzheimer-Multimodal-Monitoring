{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9ea5a1-c1df-40b2-805d-0c822544a8b9",
   "metadata": {},
   "source": [
    "# 04b - Modelos de Regresi√≥n para Score de Riesgo Compuesto\n",
    "\n",
    "**Objetivo:** Desarrollar y comparar modelos de regresi√≥n para predecir el `composite_risk_score` continuo\n",
    " \n",
    "**Modalidades integradas:**\n",
    "- Gen√©tica (APOE, biomarcadores gen√©ticos)\n",
    "- Biomarcadores (tau, ptau, ABETA)\n",
    "- Neuroimagen (PET, datos de patolog√≠a tau)\n",
    "- Actividad/Sue√±o (patrones de actividad y sue√±o)\n",
    "- Demograf√≠a (edad, g√©nero, factores de riesgo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c3224-9980-41fb-90d7-2769c2be2543",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04e432-fc8b-403f-9111-0948ab575fed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6043910-407b-46d6-87bb-b1abcc06fdb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b1430-75ee-4030-a132-996dfd23bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36cbaa7-c965-49a7-8433-3dd965db7cfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c0d41-d076-4b1e-a55c-b025938da515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de MLflow\n",
    "experiment_name = \"alzheimer_regression_models\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"üî¨ Experimento MLflow: {experiment_name}\")\n",
    "print(f\"üìä Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# %%\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b42cb-7099-47a3-8a2b-7172039dd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de paths\n",
    "DATA_PATH = \"../data/processed/\"\n",
    "MODELS_PATH = \"../models/regression/\"\n",
    "RESULTS_PATH = \"../results/regression/\"\n",
    "\n",
    "# Crear directorios si no existen\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7cb23-8132-4a33-9c9a-f06a853621e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cargar datos procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab9cab-ea31-487a-9711-f8002acd7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos procesados\n",
    "print(\"üìÅ Cargando dataset procesado...\")\n",
    "\n",
    "# Cargar el dataset final del feature engineering\n",
    "df = pd.read_csv(f\"{DATA_PATH}alzheimer_features_final.csv\")\n",
    "\n",
    "print(f\"üìä Dataset cargado: {df.shape}\")\n",
    "print(f\"üéØ Target: composite_risk_score\")\n",
    "print(f\"üìã Features disponibles: {df.shape[1] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ace30b-393e-4dc8-9831-38ba11da0a8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## An√°lisis inicial del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b407d-32f6-431c-91ab-e31a8c50098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis inicial del target\n",
    "print(\"üéØ AN√ÅLISIS DEL TARGET VARIABLE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "target_col = 'composite_risk_score'\n",
    "target_stats = df[target_col].describe()\n",
    "\n",
    "print(f\"üìà Estad√≠sticas del {target_col}:\")\n",
    "for stat, value in target_stats.items():\n",
    "    print(f\"   {stat}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Distribuci√≥n del score:\")\n",
    "print(f\"   Registros v√°lidos: {df[target_col].notna().sum():,}\")\n",
    "print(f\"   Registros faltantes: {df[target_col].isna().sum():,}\")\n",
    "print(f\"   Rango: [{df[target_col].min():.3f}, {df[target_col].max():.3f}]\")\n",
    "\n",
    "# %%\n",
    "# Visualizaci√≥n de la distribuci√≥n del target\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Histograma\n",
    "axes[0,0].hist(df[target_col].dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribuci√≥n del Composite Risk Score')\n",
    "axes[0,0].set_xlabel('Risk Score')\n",
    "axes[0,0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Box plot\n",
    "axes[0,1].boxplot(df[target_col].dropna())\n",
    "axes[0,1].set_title('Box Plot del Risk Score')\n",
    "axes[0,1].set_ylabel('Risk Score')\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(df[target_col].dropna(), dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot (Normalidad)')\n",
    "\n",
    "# Distribuci√≥n por categor√≠as de riesgo (si existe)\n",
    "if 'risk_category' in df.columns:\n",
    "    risk_cats = df.groupby('risk_category')[target_col].mean().sort_values()\n",
    "    axes[1,1].bar(risk_cats.index, risk_cats.values, alpha=0.7)\n",
    "    axes[1,1].set_title('Risk Score promedio por Categor√≠a')\n",
    "    axes[1,1].set_xlabel('Categor√≠a de Riesgo')\n",
    "    axes[1,1].set_ylabel('Risk Score promedio')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}target_distribution_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75072b7b-1ff6-4a51-b97f-2d356b13e6d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparaci√≥n de datos para modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4cced-d4a1-46bf-99de-f3f4086f0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparaci√≥n de datos para modelado\n",
    "print(\"üîß PREPARACI√ìN DE DATOS PARA MODELADO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Separar features y target\n",
    "feature_cols = [col for col in df.columns if col not in [target_col, 'risk_category']]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Eliminar registros con target faltante\n",
    "valid_mask = y.notna()\n",
    "X = X[valid_mask]\n",
    "y = y[valid_mask]\n",
    "\n",
    "print(f\"üìä Datos finales para modelado:\")\n",
    "print(f\"   Samples: {X.shape[0]:,}\")\n",
    "print(f\"   Features: {X.shape[1]:,}\")\n",
    "print(f\"   Target v√°lido: {y.notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf208ce-9cc2-49ad-abda-7e3357a0420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de missing values en features\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'missing_count': X.isnull().sum(),\n",
    "    'missing_pct': (X.isnull().sum() / len(X)) * 100\n",
    "}).sort_values('missing_pct', ascending=False)\n",
    "\n",
    "print(f\"\\nüìã Top 10 features con m√°s missing values:\")\n",
    "print(missing_analysis.head(10))\n",
    "\n",
    "# %%\n",
    "# Manejo de valores faltantes\n",
    "print(\"üîß Manejo de valores faltantes...\")\n",
    "\n",
    "# Para features num√©ricas, usar mediana\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X), \n",
    "    columns=X.columns,\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Missing values imputados\")\n",
    "print(f\"   Missing antes: {X.isnull().sum().sum():,}\")\n",
    "print(f\"   Missing despu√©s: {X_imputed.isnull().sum().sum():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb63652-59ff-42c6-8ba8-1f65155f1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n de datos\n",
    "print(\"üîÑ Divisi√≥n de datos...\")\n",
    "\n",
    "# Split estratificado basado en cuartiles del target\n",
    "y_quartiles = pd.qcut(y, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_quartiles\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=pd.qcut(y_train, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    ")\n",
    "\n",
    "print(f\"üìä Divisi√≥n de datos completada:\")\n",
    "print(f\"   Train: {X_train.shape[0]:,} samples\")\n",
    "print(f\"   Validation: {X_val.shape[0]:,} samples\")  \n",
    "print(f\"   Test: {X_test.shape[0]:,} samples\")\n",
    "\n",
    "# Verificar distribuci√≥n del target en cada split\n",
    "print(f\"\\nüìà Distribuci√≥n del target por conjunto:\")\n",
    "for name, target_set in [('Train', y_train), ('Validation', y_val), ('Test', y_test)]:\n",
    "    print(f\"   {name}: Œº={target_set.mean():.4f}, œÉ={target_set.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e657e8-0e58-4295-99af-0b6f4e28ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de features\n",
    "print(\"‚öñÔ∏è Escalado de features...\")\n",
    "\n",
    "# Usar RobustScaler para manejar outliers\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertir de vuelta a DataFrame para mantener nombres de columnas\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"‚úÖ Escalado completado con RobustScaler\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837cc70-03cf-42d5-b795-315372632b4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Definici√≥n de modelos de regresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2dba6a-64ed-4a46-9b32-269f2a139727",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ DEFINICI√ìN DE MODELOS DE REGRESI√ìN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Diccionario de modelos con hiperpar√°metros b√°sicos\n",
    "models = {\n",
    "    'linear_regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'scaled': True,\n",
    "        'description': 'Regresi√≥n Lineal cl√°sica'\n",
    "    },\n",
    "    \n",
    "    'ridge_regression': {\n",
    "        'model': Ridge(alpha=1.0, random_state=42),\n",
    "        'scaled': True,\n",
    "        'description': 'Ridge Regression con regularizaci√≥n L2'\n",
    "    },\n",
    "    \n",
    "    'lasso_regression': {\n",
    "        'model': Lasso(alpha=0.1, random_state=42, max_iter=2000),\n",
    "        'scaled': True,\n",
    "        'description': 'Lasso Regression con regularizaci√≥n L1'\n",
    "    },\n",
    "    \n",
    "    'elastic_net': {\n",
    "        'model': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=2000),\n",
    "        'scaled': True,\n",
    "        'description': 'Elastic Net con regularizaci√≥n L1 + L2'\n",
    "    },\n",
    "    \n",
    "    'random_forest': {\n",
    "        'model': RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'Random Forest con ensemble de √°rboles'\n",
    "    },\n",
    "    \n",
    "    'extra_trees': {\n",
    "        'model': ExtraTreesRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'Extra Trees con randomizaci√≥n adicional'\n",
    "    },\n",
    "    \n",
    "    'gradient_boosting': {\n",
    "        'model': GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'Gradient Boosting secuencial'\n",
    "    },\n",
    "    \n",
    "    'xgboost': {\n",
    "        'model': xgb.XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'XGBoost optimizado'\n",
    "    },\n",
    "    \n",
    "    'lightgbm': {\n",
    "        'model': lgb.LGBMRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'LightGBM r√°pido y eficiente'\n",
    "    },\n",
    "    \n",
    "    'svr': {\n",
    "        'model': SVR(kernel='rbf', C=1.0, gamma='scale'),\n",
    "        'scaled': True,\n",
    "        'description': 'Support Vector Regression'\n",
    "    },\n",
    "    \n",
    "    'knn': {\n",
    "        'model': KNeighborsRegressor(n_neighbors=5, weights='distance'),\n",
    "        'scaled': True,\n",
    "        'description': 'K-Nearest Neighbors'\n",
    "    },\n",
    "    \n",
    "    'mlp': {\n",
    "        'model': MLPRegressor(\n",
    "            hidden_layer_sizes=(100, 50),\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=500,\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1\n",
    "        ),\n",
    "        'scaled': True,\n",
    "        'description': 'Multi-Layer Perceptron (Red Neuronal)'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"üîß {len(models)} modelos definidos:\")\n",
    "for name, config in models.items():\n",
    "    print(f\"   ‚Ä¢ {name}: {config['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef042381-ea93-4f60-8650-7385b4317816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de evaluaci√≥n de modelos\n",
    "def evaluate_model(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    \"\"\"\n",
    "    Eval√∫a un modelo de regresi√≥n y retorna m√©tricas\n",
    "    \"\"\"\n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # M√©tricas\n",
    "    metrics = {\n",
    "        'train_mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'val_mse': mean_squared_error(y_val, y_val_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'val_rmse': np.sqrt(mean_squared_error(y_val, y_val_pred)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'val_mae': mean_absolute_error(y_val, y_val_pred),\n",
    "        'train_r2': r2_score(y_train, y_train_pred),\n",
    "        'val_r2': r2_score(y_val, y_val_pred)\n",
    "    }\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    metrics['cv_r2_mean'] = cv_scores.mean()\n",
    "    metrics['cv_r2_std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_train_pred, y_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5f4c4-76ce-4fec-b43d-6915da60f755",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Entrenamiento y evaluaci√≥n de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c41c50-6877-4b69-b3a1-3587cda533fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ ENTRENAMIENTO Y EVALUACI√ìN DE MODELOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = {}\n",
    "all_predictions = {}\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    print(f\"\\nüîÑ Entrenando {model_name}...\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Seleccionar datos escalados o no seg√∫n el modelo\n",
    "        if config['scaled']:\n",
    "            X_train_model = X_train_scaled\n",
    "            X_val_model = X_val_scaled\n",
    "        else:\n",
    "            X_train_model = X_train\n",
    "            X_val_model = X_val\n",
    "            \n",
    "        # Entrenar y evaluar\n",
    "        try:\n",
    "            metrics, y_train_pred, y_val_pred = evaluate_model(\n",
    "                config['model'], X_train_model, X_val_model, \n",
    "                y_train, y_val, model_name\n",
    "            )\n",
    "            \n",
    "            # Guardar resultados\n",
    "            results[model_name] = metrics\n",
    "            all_predictions[model_name] = {\n",
    "                'train_pred': y_train_pred,\n",
    "                'val_pred': y_val_pred\n",
    "            }\n",
    "            \n",
    "            # Log en MLflow\n",
    "            mlflow.log_param(\"model_type\", model_name)\n",
    "            mlflow.log_param(\"scaled_data\", config['scaled'])\n",
    "            mlflow.log_param(\"description\", config['description'])\n",
    "            mlflow.log_param(\"n_features\", X_train_model.shape[1])\n",
    "            mlflow.log_param(\"n_train_samples\", X_train_model.shape[0])\n",
    "            \n",
    "            # Log m√©tricas\n",
    "            for metric_name, value in metrics.items():\n",
    "                mlflow.log_metric(metric_name, value)\n",
    "            \n",
    "            # Log modelo\n",
    "            if model_name in ['xgboost']:\n",
    "                mlflow.xgboost.log_model(config['model'], f\"model_{model_name}\")\n",
    "            elif model_name in ['lightgbm']:\n",
    "                mlflow.lightgbm.log_model(config['model'], f\"model_{model_name}\")\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(config['model'], f\"model_{model_name}\")\n",
    "            \n",
    "            # Guardar modelo localmente\n",
    "            joblib.dump(config['model'], f\"{MODELS_PATH}{model_name}_model.pkl\")\n",
    "            \n",
    "            print(f\"   ‚úÖ {model_name} completado\")\n",
    "            print(f\"      Val R¬≤: {metrics['val_r2']:.4f}\")\n",
    "            print(f\"      Val RMSE: {metrics['val_rmse']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error en {model_name}: {str(e)}\")\n",
    "            \n",
    "print(f\"\\nüéØ Entrenamiento completado para {len(results)} modelos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c389ba4-4243-4dc1-9f3a-35e711d5a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de resultados\n",
    "print(\"üìä COMPARACI√ìN DE RESULTADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# Ordenar por R¬≤ de validaci√≥n\n",
    "results_df = results_df.sort_values('val_r2', ascending=False)\n",
    "\n",
    "print(\"üèÜ Ranking de modelos por R¬≤ de validaci√≥n:\")\n",
    "print(\"-\" * 70)\n",
    "for i, (model, row) in enumerate(results_df.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {model:20s} | R¬≤: {row['val_r2']:.4f} | RMSE: {row['val_rmse']:.4f} | MAE: {row['val_mae']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e0a735-e629-435b-be0f-4a52267159d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba752de3-9338-4522-b8a9-2ee56daf8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"{RESULTS_PATH}regression_models_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cadacf1-b5db-4479-ae34-2fff44c368f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualizaci√≥n de comparaci√≥n de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa4d03-3490-445c-ae7e-be3e299ddd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de comparaci√≥n de modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# R¬≤ Score comparison\n",
    "models_names = results_df.index[:10]  # Top 10 modelos\n",
    "train_r2 = results_df.loc[models_names, 'train_r2']\n",
    "val_r2 = results_df.loc[models_names, 'val_r2']\n",
    "\n",
    "x = np.arange(len(models_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,0].bar(x - width/2, train_r2, width, label='Train R¬≤', alpha=0.8)\n",
    "axes[0,0].bar(x + width/2, val_r2, width, label='Validation R¬≤', alpha=0.8)\n",
    "axes[0,0].set_xlabel('Modelos')\n",
    "axes[0,0].set_ylabel('R¬≤ Score')\n",
    "axes[0,0].set_title('Comparaci√≥n R¬≤ Score')\n",
    "axes[0,0].set_xticks(x)\n",
    "axes[0,0].set_xticklabels(models_names, rotation=45, ha='right')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "train_rmse = results_df.loc[models_names, 'train_rmse']\n",
    "val_rmse = results_df.loc[models_names, 'val_rmse']\n",
    "\n",
    "axes[0,1].bar(x - width/2, train_rmse, width, label='Train RMSE', alpha=0.8)\n",
    "axes[0,1].bar(x + width/2, val_rmse, width, label='Validation RMSE', alpha=0.8)\n",
    "axes[0,1].set_xlabel('Modelos')\n",
    "axes[0,1].set_ylabel('RMSE')\n",
    "axes[0,1].set_title('Comparaci√≥n RMSE')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(models_names, rotation=45, ha='right')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Overfit analysis (diferencia entre train y validation R¬≤)\n",
    "overfit_score = results_df.loc[models_names, 'train_r2'] - results_df.loc[models_names, 'val_r2']\n",
    "colors = ['red' if x > 0.1 else 'orange' if x > 0.05 else 'green' for x in overfit_score]\n",
    "\n",
    "axes[1,0].bar(models_names, overfit_score, color=colors, alpha=0.7)\n",
    "axes[1,0].set_xlabel('Modelos')\n",
    "axes[1,0].set_ylabel('Train R¬≤ - Val R¬≤')\n",
    "axes[1,0].set_title('An√°lisis de Overfitting')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].axhline(y=0.05, color='orange', linestyle='--', alpha=0.5)\n",
    "axes[1,0].axhline(y=0.1, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_means = results_df.loc[models_names, 'cv_r2_mean']\n",
    "cv_stds = results_df.loc[models_names, 'cv_r2_std']\n",
    "\n",
    "axes[1,1].bar(models_names, cv_means, yerr=cv_stds, capsize=5, alpha=0.7)\n",
    "axes[1,1].set_xlabel('Modelos')\n",
    "axes[1,1].set_ylabel('CV R¬≤ Score')\n",
    "axes[1,1].set_title('Cross-Validation R¬≤ (5-fold)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}models_comparison_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775ed61-c56d-4b39-a59f-e61e7a4d77a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## An√°lisis de predicciones del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26431f72-9822-49ed-9e39-463079fe761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.index[0]\n",
    "best_predictions = all_predictions[best_model_name]\n",
    "\n",
    "print(f\"üèÜ AN√ÅLISIS DEL MEJOR MODELO: {best_model_name}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Scatter plot real vs predicho - Training\n",
    "axes[0,0].scatter(y_train, best_predictions['train_pred'], alpha=0.6, s=20)\n",
    "axes[0,0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Valores Reales')\n",
    "axes[0,0].set_ylabel('Valores Predichos')\n",
    "axes[0,0].set_title(f'{best_model_name} - Training Set')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot real vs predicho - Validation\n",
    "axes[0,1].scatter(y_val, best_predictions['val_pred'], alpha=0.6, s=20, color='orange')\n",
    "axes[0,1].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[0,1].set_xlabel('Valores Reales')\n",
    "axes[0,1].set_ylabel('Valores Predichos')\n",
    "axes[0,1].set_title(f'{best_model_name} - Validation Set')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot - Training\n",
    "train_residuals = y_train - best_predictions['train_pred']\n",
    "axes[1,0].scatter(best_predictions['train_pred'], train_residuals, alpha=0.6, s=20)\n",
    "axes[1,0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,0].set_xlabel('Valores Predichos')\n",
    "axes[1,0].set_ylabel('Residuales')\n",
    "axes[1,0].set_title('Residuales - Training Set')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot - Validation\n",
    "val_residuals = y_val - best_predictions['val_pred']\n",
    "axes[1,1].scatter(best_predictions['val_pred'], val_residuals, alpha=0.6, s=20, color='orange')\n",
    "axes[1,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,1].set_xlabel('Valores Predichos')\n",
    "axes[1,1].set_ylabel('Residuales')\n",
    "axes[1,1].set_title('Residuales - Validation Set')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}best_model_predictions_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Feature importance del mejor modelo (si es tree-based)\n",
    "if hasattr(models[best_model_name]['model'], 'feature_importances_'):\n",
    "    print(f\"üåü FEATURE IMPORTANCE - {best_model_name}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Obtener importancias\n",
    "    if models[best_model_name]['scaled']:\n",
    "        feature_names = X_train_scaled.columns\n",
    "    else:\n",
    "        feature_names = X_train.columns\n",
    "        \n",
    "    importances = models[best_model_name]['model'].feature_importances_\n",
    "    \n",
    "    # Crear DataFrame con importancias\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Top 20 features m√°s importantes\n",
    "    top_features = feature_importance_df.head(20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=top_features, x='importance', y='feature', palette='viridis')\n",
    "    plt.title(f'Top 20 Features m√°s importantes - {best_model_name}')\n",
    "    plt.xlabel('Importancia')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_PATH}feature_importance_{best_model_name}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Guardar feature importance\n",
    "    feature_importance_df.to_csv(f\"{RESULTS_PATH}feature_importance_{best_model_name}.csv\", index=False)\n",
    "    \n",
    "    print(\"üîù Top 10 features m√°s importantes:\")\n",
    "    for i, (_, row) in enumerate(top_features.head(10).iterrows(), 1):\n",
    "        print(f\"   {i:2d}. {row['feature']:30s} | {row['importance']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3db426-111d-4cd3-af6a-521190071ff2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Guardado de objetos importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7e8cb-66b8-489d-8424-2e9e94082e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ GUARDADO DE RESULTADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Guardar el scaler\n",
    "joblib.dump(scaler, f\"{MODELS_PATH}scaler.pkl\")\n",
    "\n",
    "# Guardar configuraci√≥n de splits\n",
    "split_info = {\n",
    "    'train_indices': X_train.index.tolist(),\n",
    "    'val_indices': X_val.index.tolist(),\n",
    "    'test_indices': X_test.index.tolist(),\n",
    "    'feature_columns': X_train.columns.tolist(),\n",
    "    'target_column': target_col,\n",
    "    'best_model': best_model_name\n",
    "}\n",
    "\n",
    "with open(f\"{RESULTS_PATH}split_configuration.json\", 'w') as f:\n",
    "    json.dump(split_info, f, indent=2)\n",
    "\n",
    "# Guardar predicciones\n",
    "predictions_df = pd.DataFrame({\n",
    "    'y_train_true': y_train,\n",
    "    'y_val_true': y_val\n",
    "})\n",
    "\n",
    "for model_name, preds in all_predictions.items():\n",
    "    predictions_df[f'{model_name}_train_pred'] = preds['train_pred']\n",
    "    predictions_df[f'{model_name}_val_pred'] = preds['val_pred']\n",
    "\n",
    "predictions_df.to_csv(f\"{RESULTS_PATH}all_predictions.csv\")\n",
    "\n",
    "print(\"‚úÖ Resultados guardados:\")\n",
    "print(f\"   ‚Ä¢ Modelos: {MODELS_PATH}\")\n",
    "print(f\"   ‚Ä¢ Resultados: {RESULTS_PATH}\")\n",
    "print(f\"   ‚Ä¢ Configuraci√≥n de splits: split_configuration.json\")\n",
    "print(f\"   ‚Ä¢ Predicciones: all_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95583d8-2474-41dc-a985-a834dd0c3d34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Resumen final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad12fa-8c10-4677-9045-055ce86b5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final\n",
    "print(\"üéØ RESUMEN FINAL DEL DESARROLLO DE MODELOS DE REGRESI√ìN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"üìä Dataset procesado:\")\n",
    "print(f\"   ‚Ä¢ Registros totales: {len(X):,}\")\n",
    "print(f\"   ‚Ä¢ Features utilizadas: {X.shape[1]:,}\")\n",
    "print(f\"   ‚Ä¢ Target: {target_col}\")\n",
    "print(f\"   ‚Ä¢ Rango del target: [{y.min():.3f}, {y.max():.3f}]\")\n",
    "\n",
    "print(f\"\\nüîÑ Divisi√≥n de datos:\")\n",
    "print(f\"   ‚Ä¢ Training: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Validation: {len(X_val):,} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Test: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nü§ñ Modelos evaluados: {len(results)}\")\n",
    "for i, (model, metrics) in enumerate(results_df.head(5).iterrows(), 1):\n",
    "    print(f\"   {i}. {model:20s} | R¬≤: {metrics['val_r2']:.4f} | RMSE: {metrics['val_rmse']:.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo: {best_model_name}\")\n",
    "best_metrics = results_df.loc[best_model_name]\n",
    "print(f\"   ‚Ä¢ R¬≤ Validaci√≥n: {best_metrics['val_r2']:.4f}\")\n",
    "print(f\"   ‚Ä¢ RMSE Validaci√≥n: {best_metrics['val_rmse']:.4f}\")\n",
    "print(f\"   ‚Ä¢ MAE Validaci√≥n: {best_metrics['val_mae']:.4f}\")\n",
    "print(f\"   ‚Ä¢ CV R¬≤ (5-fold): {best_metrics['cv_r2_mean']:.4f} ¬± {best_metrics['cv_r2_std']:.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ Archivos generados:\")\n",
    "print(f\"   ‚Ä¢ Modelos entrenados: {len(results)} archivos .pkl\")\n",
    "print(f\"   ‚Ä¢ Comparaci√≥n de resultados: regression_models_comparison.csv\")\n",
    "print(f\"   ‚Ä¢ Predicciones completas: all_predictions.csv\")\n",
    "print(f\"   ‚Ä¢ Configuraci√≥n de splits: split_configuration.json\")\n",
    "print(f\"   ‚Ä¢ Visualizaciones: 4+ gr√°ficos PNG\")\n",
    "\n",
    "print(f\"\\nüî¨ MLflow:\")\n",
    "print(f\"   ‚Ä¢ Experimento: {experiment_name}\")\n",
    "print(f\"   ‚Ä¢ Runs registrados: {len(results)}\")\n",
    "print(f\"   ‚Ä¢ Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "print(f\"\\nüìà Pr√≥ximos pasos sugeridos:\")\n",
    "print(f\"   1. Evaluaci√≥n detallada en conjunto de test\")\n",
    "print(f\"   2. Optimizaci√≥n de hiperpar√°metros del mejor modelo\")\n",
    "print(f\"   3. An√°lisis de feature importance y selecci√≥n\")\n",
    "print(f\"   4. Ensemble methods con top modelos\")\n",
    "print(f\"   5. An√°lisis de explicabilidad (SHAP/LIME)\")\n",
    "\n",
    "print(f\"\\n‚úÖ NOTEBOOK 04b_regression_models.ipynb COMPLETADO\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caba989-5204-4a87-8df5-ac3dfa4c4c88",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007363e-4a35-47fc-8753-8324cd3dc0ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff19c48-7b23-403c-9293-be1f380c0766",
   "metadata": {},
   "source": [
    "__Abraham Tartalos__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
