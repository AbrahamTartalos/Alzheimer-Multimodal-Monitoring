{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78213a8f-541c-46b0-a0ec-3e74d0a2eb0a",
   "metadata": {},
   "source": [
    "# 10c - Modelos de Clasificaci√≥n para Categor√≠as de Riesgo\n",
    "\n",
    "**Objetivo:** Desarrollar modelos de clasificaci√≥n para predecir `risk_category` (Low/Moderate/High)\n",
    " \n",
    "**Enfoque:** Desarrollo de modelos base con configuraciones est√°ndar\n",
    "**Evaluaci√≥n y optimizaci√≥n:** Se realizar√° en la siguiente fase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57a538-e28c-4bea-9296-af88da7f04a9",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d97ff-efaf-42b9-a69b-ae4d668618ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8d75a-1da4-4855-9037-dc0b02ed5b3e",
   "metadata": {},
   "source": [
    "## Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9af2a-45b3-4304-95cc-4af16168689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d9460-f3d5-4ad3-b33d-2161a3d30be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n MLflow\n",
    "experiment_name = \"alzheimer_classification_models\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"üî¨ Experimento MLflow: {experiment_name}\")\n",
    "print(f\"üìä Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b90eb8-4fe0-46cc-a799-74da4481638b",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedef8b-239b-43c0-9b8d-9a6095dfc3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de paths\n",
    "DATA_PATH = \"../data/processed/\"\n",
    "MODELS_PATH = \"../models/classification/\"\n",
    "RESULTS_PATH = \"../results/classification/\"\n",
    "\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87524d36-c678-4065-a7f0-bbb3337dd9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "print(\"üìÅ Cargando dataset...\")\n",
    "df = pd.read_csv(f\"{DATA_PATH}alzheimer_features_final.csv\")\n",
    "\n",
    "print(f\"üìä Dataset: {df.shape}\")\n",
    "print(f\"üéØ Target: risk_category\")\n",
    "\n",
    "# %%\n",
    "# An√°lisis del target categ√≥rico\n",
    "target_col = 'risk_category'\n",
    "target_counts = df[target_col].value_counts()\n",
    "\n",
    "print(\"üéØ AN√ÅLISIS DEL TARGET CATEG√ìRICO\")\n",
    "print(\"=\"*40)\n",
    "print(f\"üìä Distribuci√≥n de {target_col}:\")\n",
    "for category, count in target_counts.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"   {category}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìã Clases disponibles: {df[target_col].unique()}\")\n",
    "print(f\"üî¢ N√∫mero de clases: {df[target_col].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e33b2-84f1-4446-8927-e6961ba1e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de distribuci√≥n de clases\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Distribuci√≥n de clases\n",
    "target_counts.plot(kind='bar', ax=axes[0], color='skyblue', alpha=0.8)\n",
    "axes[0].set_title('Distribuci√≥n de Categor√≠as de Riesgo')\n",
    "axes[0].set_xlabel('Categor√≠a de Riesgo')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Distribuci√≥n porcentual\n",
    "target_pct = (target_counts / target_counts.sum()) * 100\n",
    "target_pct.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Distribuci√≥n Porcentual')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}target_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d1513-8882-4b0a-9f92-aa0914c4338a",
   "metadata": {},
   "source": [
    "## Preparaci√≥n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410e19e-e410-4bed-b4a1-e56154827c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß PREPARACI√ìN DE DATOS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Features y target\n",
    "feature_cols = [col for col in df.columns if col not in [target_col, 'composite_risk_score']]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Eliminar registros con target faltante\n",
    "valid_mask = y.notna()\n",
    "X = X[valid_mask]\n",
    "y = y[valid_mask]\n",
    "\n",
    "print(f\"üìä Datos finales:\")\n",
    "print(f\"   Samples: {X.shape[0]:,}\")\n",
    "print(f\"   Features: {X.shape[1]:,}\")\n",
    "print(f\"   Clases: {y.nunique()}\")\n",
    "\n",
    "# %%\n",
    "# Encoding del target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"üî§ Encoding de clases:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    print(f\"   {class_name} ‚Üí {i}\")\n",
    "\n",
    "# %%\n",
    "# Manejo de valores faltantes\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X), \n",
    "    columns=X.columns, \n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Missing values imputados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0220b11-aeed-4224-9e90-bddcdb916f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n estratificada de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"üìä Divisi√≥n estratificada:\")\n",
    "print(f\"   Train: {X_train.shape[0]:,}\")\n",
    "print(f\"   Validation: {X_val.shape[0]:,}\")\n",
    "print(f\"   Test: {X_test.shape[0]:,}\")\n",
    "\n",
    "# Verificar distribuci√≥n en cada split\n",
    "for name, y_split in [('Train', y_train), ('Val', y_val), ('Test', y_test)]:\n",
    "    unique, counts = np.unique(y_split, return_counts=True)\n",
    "    dist = (counts / counts.sum()) * 100\n",
    "    print(f\"   {name}: {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5234fd-e3ee-437d-a8d2-97be67345c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train), \n",
    "    columns=X_train.columns, \n",
    "    index=X_train.index\n",
    ")\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val), \n",
    "    columns=X_val.columns, \n",
    "    index=X_val.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test), \n",
    "    columns=X_test.columns, \n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"‚öñÔ∏è Escalado completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2159db-390b-4989-9e6a-e541d369e95d",
   "metadata": {},
   "source": [
    "## Definici√≥n de modelos de clasificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ef055-fcbc-43d0-9089-f829b102767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de modelos de clasificaci√≥n\n",
    "print(\"ü§ñ DEFINICI√ìN DE MODELOS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "models = {\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'scaled': True,\n",
    "        'description': 'Regresi√≥n Log√≠stica'\n",
    "    },\n",
    "    \n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'Random Forest'\n",
    "    },\n",
    "    \n",
    "    'extra_trees': {\n",
    "        'model': ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'Extra Trees'\n",
    "    },\n",
    "    \n",
    "    'gradient_boosting': {\n",
    "        'model': GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'Gradient Boosting'\n",
    "    },\n",
    "    \n",
    "    'xgboost': {\n",
    "        'model': xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'XGBoost'\n",
    "    },\n",
    "    \n",
    "    'lightgbm': {\n",
    "        'model': lgb.LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'LightGBM'\n",
    "    },\n",
    "    \n",
    "    'svm': {\n",
    "        'model': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "        'scaled': True,\n",
    "        'description': 'Support Vector Machine'\n",
    "    },\n",
    "    \n",
    "    'knn': {\n",
    "        'model': KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
    "        'scaled': True,\n",
    "        'description': 'K-Nearest Neighbors'\n",
    "    },\n",
    "    \n",
    "    'naive_bayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'scaled': True,\n",
    "        'description': 'Naive Bayes'\n",
    "    },\n",
    "    \n",
    "    'decision_tree': {\n",
    "        'model': DecisionTreeClassifier(\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'scaled': False,\n",
    "        'description': 'Decision Tree'\n",
    "    },\n",
    "    \n",
    "    'mlp': {\n",
    "        'model': MLPClassifier(\n",
    "            hidden_layer_sizes=(100, 50),\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=500,\n",
    "            random_state=42,\n",
    "            early_stopping=True\n",
    "        ),\n",
    "        'scaled': True,\n",
    "        'description': 'Multi-Layer Perceptron'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"üîß {len(models)} modelos definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5d037-9c9b-4192-9aea-d3997b659be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de evaluaci√≥n\n",
    "def evaluate_classifier(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    \"\"\"Eval√∫a un modelo de clasificaci√≥n\"\"\"\n",
    "    \n",
    "    # Entrenar\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # M√©tricas\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Precision, Recall, F1 por clase\n",
    "    train_prf = precision_recall_fscore_support(y_train, y_train_pred, average='weighted')\n",
    "    val_prf = precision_recall_fscore_support(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train, y_train, \n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    metrics = {\n",
    "        'train_accuracy': train_acc,\n",
    "        'val_accuracy': val_acc,\n",
    "        'train_precision': train_prf[0],\n",
    "        'val_precision': val_prf[0],\n",
    "        'train_recall': train_prf[1],\n",
    "        'val_recall': val_prf[1],\n",
    "        'train_f1': train_prf[2],\n",
    "        'val_f1': val_prf[2],\n",
    "        'cv_accuracy_mean': cv_scores.mean(),\n",
    "        'cv_accuracy_std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    return metrics, y_train_pred, y_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a47cbb-0930-44a2-ad68-ee75f90c556b",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1288bc5-385a-45bb-af83-63a178ebc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de modelos\n",
    "print(\"üöÄ ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "results = {}\n",
    "all_predictions = {}\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    print(f\"\\nüîÑ {model_name}...\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Seleccionar datos\n",
    "        if config['scaled']:\n",
    "            X_train_model = X_train_scaled\n",
    "            X_val_model = X_val_scaled\n",
    "        else:\n",
    "            X_train_model = X_train\n",
    "            X_val_model = X_val\n",
    "            \n",
    "        try:\n",
    "            # Entrenar y evaluar\n",
    "            metrics, y_train_pred, y_val_pred = evaluate_classifier(\n",
    "                config['model'], X_train_model, X_val_model,\n",
    "                y_train, y_val, model_name\n",
    "            )\n",
    "            \n",
    "            # Guardar resultados\n",
    "            results[model_name] = metrics\n",
    "            all_predictions[model_name] = {\n",
    "                'train_pred': y_train_pred,\n",
    "                'val_pred': y_val_pred\n",
    "            }\n",
    "            \n",
    "            # MLflow logging\n",
    "            mlflow.log_param(\"model_type\", model_name)\n",
    "            mlflow.log_param(\"scaled_data\", config['scaled'])\n",
    "            mlflow.log_param(\"n_classes\", len(le.classes_))\n",
    "            mlflow.log_param(\"n_features\", X_train_model.shape[1])\n",
    "            \n",
    "            for metric_name, value in metrics.items():\n",
    "                mlflow.log_metric(metric_name, value)\n",
    "            \n",
    "            # Log modelo\n",
    "            if model_name == 'xgboost':\n",
    "                mlflow.xgboost.log_model(config['model'], f\"model_{model_name}\")\n",
    "            elif model_name == 'lightgbm':\n",
    "                mlflow.lightgbm.log_model(config['model'], f\"model_{model_name}\")\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(config['model'], f\"model_{model_name}\")\n",
    "            \n",
    "            # Guardar localmente\n",
    "            joblib.dump(config['model'], f\"{MODELS_PATH}{model_name}_classifier.pkl\")\n",
    "            \n",
    "            print(f\"   ‚úÖ Accuracy: {metrics['val_accuracy']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\nüéØ Entrenamiento completado: {len(results)} modelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011ec8c-dfa7-4c92-a82c-b1dd9dfe4dcb",
   "metadata": {},
   "source": [
    "## Comparaci√≥n de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247bcf03-8633-4f1d-9154-f70106e06ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de resultados\n",
    "print(\"üìä COMPARACI√ìN DE RESULTADOS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "results_df = pd.DataFrame(results).T.sort_values('val_accuracy', ascending=False)\n",
    "\n",
    "print(\"üèÜ Ranking por Accuracy de validaci√≥n:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (model, row) in enumerate(results_df.head(8).iterrows(), 1):\n",
    "    print(f\"{i}. {model:20s} | Acc: {row['val_accuracy']:.4f} | F1: {row['val_f1']:.4f}\")\n",
    "\n",
    "# Guardar resultados\n",
    "results_df.to_csv(f\"{RESULTS_PATH}classification_models_comparison.csv\")\n",
    "\n",
    "# %%\n",
    "# Visualizaci√≥n de comparaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "models_top = results_df.index[:8]\n",
    "\n",
    "# Accuracy comparison\n",
    "train_acc = results_df.loc[models_top, 'train_accuracy']\n",
    "val_acc = results_df.loc[models_top, 'val_accuracy']\n",
    "\n",
    "x = np.arange(len(models_top))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,0].bar(x - width/2, train_acc, width, label='Train', alpha=0.8)\n",
    "axes[0,0].bar(x + width/2, val_acc, width, label='Validation', alpha=0.8)\n",
    "axes[0,0].set_title('Accuracy Comparison')\n",
    "axes[0,0].set_xticks(x)\n",
    "axes[0,0].set_xticklabels(models_top, rotation=45, ha='right')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score comparison\n",
    "train_f1 = results_df.loc[models_top, 'train_f1']\n",
    "val_f1 = results_df.loc[models_top, 'val_f1']\n",
    "\n",
    "axes[0,1].bar(x - width/2, train_f1, width, label='Train', alpha=0.8)\n",
    "axes[0,1].bar(x + width/2, val_f1, width, label='Validation', alpha=0.8)\n",
    "axes[0,1].set_title('F1 Score Comparison')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(models_top, rotation=45, ha='right')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting analysis\n",
    "overfit_score = results_df.loc[models_top, 'train_accuracy'] - results_df.loc[models_top, 'val_accuracy']\n",
    "colors = ['red' if x > 0.1 else 'orange' if x > 0.05 else 'green' for x in overfit_score]\n",
    "\n",
    "axes[1,0].bar(models_top, overfit_score, color=colors, alpha=0.7)\n",
    "axes[1,0].set_title('Overfitting Analysis')\n",
    "axes[1,0].set_ylabel('Train Acc - Val Acc')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_means = results_df.loc[models_top, 'cv_accuracy_mean']\n",
    "cv_stds = results_df.loc[models_top, 'cv_accuracy_std']\n",
    "\n",
    "axes[1,1].bar(models_top, cv_means, yerr=cv_stds, capsize=5, alpha=0.7)\n",
    "axes[1,1].set_title('Cross-Validation Accuracy')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}models_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c422d17-587d-4867-a75c-948a0ff3e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n del mejor modelo\n",
    "best_model_name = results_df.index[0]\n",
    "best_predictions = all_predictions[best_model_name]\n",
    "\n",
    "print(f\"üèÜ MEJOR MODELO: {best_model_name}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Matriz de confusi√≥n para validaci√≥n\n",
    "cm = confusion_matrix(y_val, best_predictions['val_pred'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(f'Matriz de Confusi√≥n - {best_model_name}')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.ylabel('Real')\n",
    "plt.savefig(f\"{RESULTS_PATH}confusion_matrix_{best_model_name}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af72724-5d9f-4d2e-8124-82e812e8a222",
   "metadata": {},
   "source": [
    "## Feature importance (si disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a4ee9-8ab8-4649-ab4c-91be11ec2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (si disponible)\n",
    "if hasattr(models[best_model_name]['model'], 'feature_importances_'):\n",
    "    print(f\"üåü FEATURE IMPORTANCE - {best_model_name}\")\n",
    "    \n",
    "    importances = models[best_model_name]['model'].feature_importances_\n",
    "    feature_names = X_train.columns if not models[best_model_name]['scaled'] else X_train_scaled.columns\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Top 15 features\n",
    "    top_features = importance_df.head(15)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=top_features, x='importance', y='feature')\n",
    "    plt.title(f'Top 15 Features - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_PATH}feature_importance_{best_model_name}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    importance_df.to_csv(f\"{RESULTS_PATH}feature_importance_{best_model_name}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6804bd6-be0d-44bb-bb05-9d1dc2371052",
   "metadata": {},
   "source": [
    "## Guardado de configuraci√≥n y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6eab4-c8e0-4c37-aacb-1d58c20407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de configuraci√≥n y resultados\n",
    "print(\"üíæ GUARDADO DE RESULTADOS\")\n",
    "\n",
    "# Guardar scaler y encoder\n",
    "joblib.dump(scaler, f\"{MODELS_PATH}scaler_classification.pkl\")\n",
    "joblib.dump(le, f\"{MODELS_PATH}label_encoder.pkl\")\n",
    "\n",
    "# Configuraci√≥n de splits\n",
    "split_config = {\n",
    "    'train_indices': X_train.index.tolist(),\n",
    "    'val_indices': X_val.index.tolist(),\n",
    "    'test_indices': X_test.index.tolist(),\n",
    "    'feature_columns': X_train.columns.tolist(),\n",
    "    'target_column': target_col,\n",
    "    'classes': le.classes_.tolist(),\n",
    "    'best_model': best_model_name\n",
    "}\n",
    "\n",
    "with open(f\"{RESULTS_PATH}classification_split_config.json\", 'w') as f:\n",
    "    json.dump(split_config, f, indent=2)\n",
    "\n",
    "# Predicciones\n",
    "pred_df = pd.DataFrame({\n",
    "    'y_train_true': y_train,\n",
    "    'y_val_true': y_val\n",
    "})\n",
    "\n",
    "for model_name, preds in all_predictions.items():\n",
    "    pred_df[f'{model_name}_train_pred'] = preds['train_pred']\n",
    "    pred_df[f'{model_name}_val_pred'] = preds['val_pred']\n",
    "\n",
    "pred_df.to_csv(f\"{RESULTS_PATH}classification_predictions.csv\")\n",
    "\n",
    "print(\"‚úÖ Guardado completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615f8b8-33da-4b09-a4a6-f4dfea59d99d",
   "metadata": {},
   "source": [
    "## Resumen final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065e17f-1f75-49fb-bca7-49d989c2d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final\n",
    "print(\"üéØ RESUMEN FINAL - CLASIFICACI√ìN\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(f\"üìä Dataset:\")\n",
    "print(f\"   ‚Ä¢ Samples: {len(X):,}\")\n",
    "print(f\"   ‚Ä¢ Features: {X.shape[1]:,}\")\n",
    "print(f\"   ‚Ä¢ Clases: {len(le.classes_)} ({', '.join(le.classes_)})\")\n",
    "\n",
    "print(f\"\\nü§ñ Modelos evaluados: {len(results)}\")\n",
    "print(f\"üèÜ Mejor modelo: {best_model_name}\")\n",
    "best_metrics = results_df.loc[best_model_name]\n",
    "print(f\"   ‚Ä¢ Accuracy: {best_metrics['val_accuracy']:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {best_metrics['val_f1']:.4f}\")\n",
    "print(f\"   ‚Ä¢ CV Accuracy: {best_metrics['cv_accuracy_mean']:.4f} ¬± {best_metrics['cv_accuracy_std']:.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ Archivos generados:\")\n",
    "print(f\"   ‚Ä¢ {len(results)} modelos entrenados\")\n",
    "print(f\"   ‚Ä¢ Comparaci√≥n: classification_models_comparison.csv\")\n",
    "print(f\"   ‚Ä¢ Predicciones: classification_predictions.csv\")\n",
    "print(f\"   ‚Ä¢ Configuraci√≥n: classification_split_config.json\")\n",
    "\n",
    "print(f\"\\n‚úÖ NOTEBOOK 04c_classification_models.ipynb COMPLETADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea49671-6862-465d-b167-7d9376375a4d",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd92a04-76e6-4e89-a049-50109034d6e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683824d-8d44-4159-bfde-39748ef333a3",
   "metadata": {},
   "source": [
    "__Abraham Tartalos__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
