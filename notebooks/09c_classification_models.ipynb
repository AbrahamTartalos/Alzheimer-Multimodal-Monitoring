{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78213a8f-541c-46b0-a0ec-3e74d0a2eb0a",
   "metadata": {},
   "source": [
    "# 04c - Classification Models Development\n",
    "\n",
    "**Objetivo**: Desarrollar modelos de clasificación para predecir categorías de riesgo de Alzheimer (Low, Moderate, High)\n",
    " \n",
    "**Target Variable**: `risk_category`\n",
    "**Clases**: Low (46.4%), Moderate (46.1%), High (7.5%)\n",
    " \n",
    "**Modelos a desarrollar**:\n",
    "- Logistic Regression (baseline)\n",
    "- Random Forest Classifier\n",
    "- Gradient Boosting (XGBoost, LightGBM)\n",
    "- Support Vector Machine\n",
    "- Neural Network (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57a538-e28c-4bea-9296-af88da7f04a9",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d97ff-efaf-42b9-a69b-ae4d668618ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8d75a-1da4-4855-9037-dc0b02ed5b3e",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd9af2a-45b3-4304-95cc-4af16168689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src/modeling')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import model_utils\n",
    "# Importar scripts personalizados\n",
    "from classification_pipeline import ClassificationPipeline\n",
    "from ensemble_methods import AlzheimerEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440d9460-f3d5-4ad3-b33d-2161a3d30be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d8716f-36d0-4aa3-ae3c-5718b035b040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Librerías y scripts importados correctamente\n",
      "📅 Fecha de ejecución: 2025-06-22 18:18:38\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Librerías y scripts importados correctamente\")\n",
    "print(f\"📅 Fecha de ejecución: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b90eb8-4fe0-46cc-a799-74da4481638b",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bedef8b-239b-43c0-9b8d-9a6095dfc3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dataset cargado: (48466, 186)\n",
      "🎯 Distribución de clases:\n",
      "risk_category\n",
      "Low         22501\n",
      "Moderate    22345\n",
      "High         3620\n",
      "Name: count, dtype: int64\n",
      "📊 Porcentajes:\n",
      "risk_category\n",
      "Low         46.4\n",
      "Moderate    46.1\n",
      "High         7.5\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos procesados\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/features/alzheimer_features_selected_20250621.csv')\n",
    "    print(f\"📊 Dataset cargado: {df.shape}\")\n",
    "    \n",
    "    # Verificar target variable\n",
    "    if 'risk_category' in df.columns:\n",
    "        print(f\"🎯 Distribución de clases:\")\n",
    "        class_dist = df['risk_category'].value_counts()\n",
    "        print(class_dist)\n",
    "        print(f\"📊 Porcentajes:\")\n",
    "        print((class_dist / len(df) * 100).round(1))\n",
    "    else:\n",
    "        print(\"❌ Error: Variable target 'risk_category' no encontrada\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: Archivo de features no encontrado\")\n",
    "    print(\"💡 Ejecuta primero el notebook 03_feature_engineering_master.ipynb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2159db-390b-4989-9e6a-e541d369e95d",
   "metadata": {},
   "source": [
    "## Inicializar Pipeline de Clasificaión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52f8231-e95a-4c8e-937a-5caf3205e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar pipeline de clasificación\n",
    "classification_pipeline = ClassificationPipeline()\n",
    "ensemble_methods = AlzheimerEnsemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011ec8c-dfa7-4c92-a82c-b1dd9dfe4dcb",
   "metadata": {},
   "source": [
    "## Ejecutar Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "247bcf03-8633-4f1d-9154-f70106e06ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ejecutando pipeline completo de clasificación...\n",
      "🚀 Iniciando pipeline de clasificación...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert [['Female' 'Female' 'Female' ... 'Male' 'Male' 'Male']\n [nan '2005-11-01 00:00:00' '2005-11-01 00:00:00' ... '2006-10-17'\n  '2006-10-17' '2006-10-17']\n [nan 'S_122' 'S_122' ... 'S_065' 'S_065' 'S_065']\n ...\n ['Superior' 'Básica' 'Básica' ... 'Básica' 'Básica' 'Básica']\n [nan '2005-11-01 00:00:00' '2005-11-01 00:00:00' ... '2006-10-17'\n  '2006-10-17' '2006-10-17']\n [nan 'F' 'F' ... 'M' 'M' 'M']] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejecutar el pipeline completo\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 Ejecutando pipeline completo de clasificación...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m pipeline_results \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrisk_category\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Obtener resultados\u001b[39;00m\n\u001b[0;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m pipeline_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mE:\\usuarios\\alumno\\Escritorio\\Alzheimer-Multimodal-Monitoring\\notebooks\\../src/modeling\\classification_pipeline.py:275\u001b[0m, in \u001b[0;36mClassificationPipeline.run_pipeline\u001b[1;34m(self, df, target_col)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 Iniciando pipeline de clasificación...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Preparar datos\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Datos preparados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Entrenar modelos\u001b[39;00m\n",
      "File \u001b[1;32mE:\\usuarios\\alumno\\Escritorio\\Alzheimer-Multimodal-Monitoring\\notebooks\\../src/modeling\\classification_pipeline.py:68\u001b[0m, in \u001b[0;36mClassificationPipeline.prepare_data\u001b[1;34m(self, df, target_col, test_size)\u001b[0m\n\u001b[0;32m     65\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[:, X\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m<\u001b[39m null_threshold]\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Rellenar valores nulos con mediana\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mfillna(\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# División train/test estratificada\u001b[39;00m\n\u001b[0;32m     71\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     72\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39mtest_size, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m     73\u001b[0m )\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\frame.py:11706\u001b[0m, in \u001b[0;36mDataFrame.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11698\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  11700\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11704\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11705\u001b[0m ):\n\u001b[1;32m> 11706\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmedian(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11708\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\generic.py:12431\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  12425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12426\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmedian, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12433\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\pandas\\core\\nanops.py:787\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    785\u001b[0m     inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values)\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 787\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    789\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert [['Female' 'Female' 'Female' ... 'Male' 'Male' 'Male']\n [nan '2005-11-01 00:00:00' '2005-11-01 00:00:00' ... '2006-10-17'\n  '2006-10-17' '2006-10-17']\n [nan 'S_122' 'S_122' ... 'S_065' 'S_065' 'S_065']\n ...\n ['Superior' 'Básica' 'Básica' ... 'Básica' 'Básica' 'Básica']\n [nan '2005-11-01 00:00:00' '2005-11-01 00:00:00' ... '2006-10-17'\n  '2006-10-17' '2006-10-17']\n [nan 'F' 'F' ... 'M' 'M' 'M']] to numeric"
     ]
    }
   ],
   "source": [
    "# Ejecutar el pipeline completo\n",
    "print(\"🚀 Ejecutando pipeline completo de clasificación...\")\n",
    "pipeline_results = classification_pipeline.run_pipeline(df, target_col='risk_category')\n",
    "\n",
    "# Obtener resultados\n",
    "results = pipeline_results['results']\n",
    "cv_results = pipeline_results['cv_results']\n",
    "trained_models = pipeline_results['trained_models']\n",
    "best_model_name = pipeline_results['best_model']\n",
    "\n",
    "print(f\"🏆 Mejor modelo seleccionado: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008a2b0-0ecb-484c-891c-ea6f176629ac",
   "metadata": {},
   "source": [
    "## Recopilar métricas de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8484219-c09e-479d-a366-f6b681d99463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recopilar métricas de rendimiento\n",
    "performance_comparison = {}\n",
    "for name, metrics in results.items():\n",
    "    performance_comparison[name] = metrics['f1_weighted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5674c6-5f2d-43b4-b584-8cc00bfa4583",
   "metadata": {},
   "source": [
    "## Ensamblaje de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58258982-f286-4787-8581-6765de0afeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ensamblaje de modelos\n",
    "with mlflow.start_run(run_name=\"ensemble_classification\"):\n",
    "    mlflow.set_tag(\"model_family\", \"ensemble\")\n",
    "    mlflow.set_tag(\"model_type\", \"classification\")\n",
    "    \n",
    "    print(\"🚀 Creando modelos ensemble...\")\n",
    "    \n",
    "    # Recopilar mejores modelos entrenados\n",
    "    best_models = {\n",
    "        'logistic_regression': trained_models['logistic_regression'],\n",
    "        'random_forest': trained_models['random_forest'],\n",
    "        'gradient_boosting': trained_models['gradient_boosting'],\n",
    "        'svm': trained_models['svm']\n",
    "    }\n",
    "    \n",
    "    # Preparar datos completos\n",
    "    X_train, X_test, y_train, y_test = classification_pipeline.prepare_data(df)\n",
    "    X_full = pd.concat([X_train, X_test])\n",
    "    y_full = pd.concat([y_train, y_test])\n",
    "    \n",
    "    # Voting Classifier\n",
    "    voting_results = ensemble_methods.create_voting_ensemble(\n",
    "        best_models, X_full, y_full, cv_folds=5\n",
    "    )\n",
    "    \n",
    "    # Stacking Classifier\n",
    "    stacking_results = ensemble_methods.create_stacking_classifier(\n",
    "        best_models, X_full, y_full, cv_folds=5\n",
    "    )\n",
    "    \n",
    "    # Registrar resultados\n",
    "    mlflow.log_metrics({\n",
    "        'voting_f1_weighted': voting_results['cv_scores']['f1_weighted'],\n",
    "        'voting_accuracy': voting_results['cv_scores']['accuracy'],\n",
    "        'stacking_f1_weighted': stacking_results['cv_scores']['f1_weighted'],\n",
    "        'stacking_accuracy': stacking_results['cv_scores']['accuracy']\n",
    "    })\n",
    "    \n",
    "    mlflow.sklearn.log_model(voting_results['model'], \"voting_classifier\")\n",
    "    mlflow.sklearn.log_model(stacking_results['model'], \"stacking_classifier\")\n",
    "    \n",
    "    # Añadir resultados de ensamblaje a la comparación\n",
    "    performance_comparison['Voting Ensemble'] = voting_results['cv_scores']['f1_weighted']\n",
    "    performance_comparison['Stacking Ensemble'] = stacking_results['cv_scores']['f1_weighted']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af72724-5d9f-4d2e-8124-82e812e8a222",
   "metadata": {},
   "source": [
    "## Análisis de Importancia de Características (Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a4ee9-8ab8-4649-ab4c-91be11ec2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de importancia de características (para modelos tree-based)\n",
    "print(\"\\n🔍 ANÁLISIS DE IMPORTANCIA DE FEATURES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Obtener nombres de características\n",
    "exclude_cols = ['composite_risk_score', 'risk_category']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "# Combinar importancias de modelos\n",
    "combined_importance = pd.DataFrame()\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    if hasattr(model.named_steps['classifier'], 'feature_importances_'):\n",
    "        importance = model_utils.get_feature_importance(\n",
    "            model.named_steps['classifier'], feature_cols\n",
    "        )\n",
    "        combined_importance[name] = importance.set_index('feature')['importance']\n",
    "\n",
    "if not combined_importance.empty:\n",
    "    combined_importance['Mean_Importance'] = combined_importance.mean(axis=1)\n",
    "    top_features = combined_importance.nlargest(15, 'Mean_Importance')\n",
    "    \n",
    "    # Visualización y guardado de resultados\n",
    "    print(\"🎯 Top 15 Features más importantes:\")\n",
    "    print(top_features[['Mean_Importance']].round(4))\n",
    "    \n",
    "    # Visualización\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features['Mean_Importance'].plot(kind='barh', color='lightgreen')\n",
    "    plt.title('Top 15 Features - Importancia Promedio')\n",
    "    plt.xlabel('Importancia Promedio')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6804bd6-be0d-44bb-bb05-9d1dc2371052",
   "metadata": {},
   "source": [
    "## Comparación Final de Modelos (agregando los ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6eab4-c8e0-4c37-aacb-1d58c20407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 COMPARACIÓN FINAL DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': model, 'F1_Score_Weighted': score} \n",
    "    for model, score in performance_comparison.items()\n",
    "]).sort_values('F1_Score_Weighted', ascending=False)\n",
    "\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualización de comparación\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(comparison_df['Model'], comparison_df['F1_Score_Weighted'], \n",
    "               color='lightcoral', alpha=0.8)\n",
    "plt.title('Comparación de Rendimiento - Modelos de Clasificación')\n",
    "plt.xlabel('Modelo')\n",
    "plt.ylabel('F1-Score Weighted')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for bar, score in zip(bars, comparison_df['F1_Score_Weighted']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "             f'{score:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615f8b8-33da-4b09-a4a6-f4dfea59d99d",
   "metadata": {},
   "source": [
    "## Resumen final y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b284bf1-eae6-4718-b99d-f53704508621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final y recomendaciones\n",
    "best_model = comparison_df.iloc[0]['Model']\n",
    "best_score = comparison_df.iloc[0]['F1_Score_Weighted']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 RESUMEN FINAL - MODELOS DE CLASIFICACIÓN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"🏆 Mejor modelo: {best_model}\")\n",
    "print(f\"📊 F1-Score Weighted: {best_score:.4f}\")\n",
    "print(f\"📈 Mejora sobre baseline: {((best_score - lr_performance) / lr_performance * 100):.1f}%\")\n",
    "print(f\"⚖️ Desbalanceamiento de clases: {imbalance_ratio:.2f}\")\n",
    "print(f\"🎯 Total de modelos entrenados: {len(performance_comparison)}\")\n",
    "\n",
    "print(\"\\n💡 RECOMENDACIONES:\")\n",
    "if best_score > 0.85:\n",
    "    print(\"✅ Excelente rendimiento alcanzado\")\n",
    "elif best_score > 0.75:\n",
    "    print(\"⚠️ Buen rendimiento, considerar optimización en Fase 5\")\n",
    "else:\n",
    "    print(\"❌ Rendimiento bajo, requiere optimización en Fase 5\")\n",
    "\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"⚖️ Considerar técnicas de balanceamiento adicionales\")\n",
    "\n",
    "print(\"\\n🔄 Listo para Fase 5: Evaluación y Optimización\")\n",
    "print(\"📁 Todos los modelos guardados en MLflow\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc956bf4-f1f0-4459-a108-b25b5866412f",
   "metadata": {},
   "source": [
    "## Guardado de Archivos Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1d0b5-b90c-4238-8393-7ea842323335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar métricas finales\n",
    "final_metrics = {\n",
    "    'best_model': best_model,\n",
    "    'best_f1_score': best_score,\n",
    "    'baseline_f1_score': lr_performance,\n",
    "    'improvement_percentage': (best_score - lr_performance) / lr_performance * 100,\n",
    "    'models_trained': len(performance_comparison),\n",
    "    'imbalance_ratio': imbalance_ratio,\n",
    "    'training_samples': len(X),\n",
    "    'features_used': len(feature_cols)\n",
    "}\n",
    "\n",
    "# Guardar en archivo\n",
    "pd.Series(final_metrics).to_csv('../reports/model_results/classification_summary.csv')\n",
    "print(\"📁 Métricas guardadas en: ../reports/model_results/classification_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea49671-6862-465d-b167-7d9376375a4d",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd92a04-76e6-4e89-a049-50109034d6e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683824d-8d44-4159-bfde-39748ef333a3",
   "metadata": {},
   "source": [
    "__Abraham Tartalos__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
