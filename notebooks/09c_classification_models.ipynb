{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78213a8f-541c-46b0-a0ec-3e74d0a2eb0a",
   "metadata": {},
   "source": [
    "# 04c - Classification Models Development\n",
    "\n",
    "**Objetivo**: Desarrollar modelos de clasificaci√≥n para predecir categor√≠as de riesgo de Alzheimer (Low, Moderate, High)\n",
    " \n",
    "**Target Variable**: `risk_category`\n",
    "**Clases**: Low (46.4%), Moderate (46.1%), High (7.5%)\n",
    " \n",
    "**Modelos a desarrollar**:\n",
    "- Logistic Regression (baseline)\n",
    "- Random Forest Classifier\n",
    "- Gradient Boosting (XGBoost, LightGBM)\n",
    "- Support Vector Machine\n",
    "- Neural Network (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57a538-e28c-4bea-9296-af88da7f04a9",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d97ff-efaf-42b9-a69b-ae4d668618ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8d75a-1da4-4855-9037-dc0b02ed5b3e",
   "metadata": {},
   "source": [
    "## Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd9af2a-45b3-4304-95cc-4af16168689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src/modeling')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import StackingClassifier  # Import expl√≠cito por si acaso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import model_utils\n",
    "# Importar scripts personalizados\n",
    "from classification_pipeline import ClassificationPipeline\n",
    "from ensemble_methods import AlzheimerEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e86347b-8ef9-438a-9dc8-437ce9dfec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440d9460-f3d5-4ad3-b33d-2161a3d30be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d8716f-36d0-4aa3-ae3c-5718b035b040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as y scripts importados correctamente\n",
      "üìÖ Fecha de ejecuci√≥n: 2025-06-22 18:18:38\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Librer√≠as y scripts importados correctamente\")\n",
    "print(f\"üìÖ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b90eb8-4fe0-46cc-a799-74da4481638b",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bedef8b-239b-43c0-9b8d-9a6095dfc3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset cargado: (48466, 186)\n",
      "üéØ Distribuci√≥n de clases:\n",
      "risk_category\n",
      "Low         22501\n",
      "Moderate    22345\n",
      "High         3620\n",
      "Name: count, dtype: int64\n",
      "üìä Porcentajes:\n",
      "risk_category\n",
      "Low         46.4\n",
      "Moderate    46.1\n",
      "High         7.5\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos procesados\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/features/alzheimer_features_selected_20250621.csv')\n",
    "    print(f\"üìä Dataset cargado: {df.shape}\")\n",
    "    \n",
    "    # Verificar target variable\n",
    "    if 'risk_category' in df.columns:\n",
    "        print(f\"üéØ Distribuci√≥n de clases:\")\n",
    "        class_dist = df['risk_category'].value_counts()\n",
    "        print(class_dist)\n",
    "        print(f\"üìä Porcentajes:\")\n",
    "        print((class_dist / len(df) * 100).round(1))\n",
    "    else:\n",
    "        print(\"‚ùå Error: Variable target 'risk_category' no encontrada\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Archivo de features no encontrado\")\n",
    "    print(\"üí° Ejecuta primero el notebook 03_feature_engineering_master.ipynb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2159db-390b-4989-9e6a-e541d369e95d",
   "metadata": {},
   "source": [
    "## Inicializar Pipeline de Clasificai√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52f8231-e95a-4c8e-937a-5caf3205e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar pipeline de clasificaci√≥n\n",
    "classification_pipeline = ClassificationPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011ec8c-dfa7-4c92-a82c-b1dd9dfe4dcb",
   "metadata": {},
   "source": [
    "## Ejecutar Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247bcf03-8633-4f1d-9154-f70106e06ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ejecutando pipeline completo de clasificaci√≥n...\n",
      "üöÄ Iniciando pipeline de clasificaci√≥n...\n",
      "üìä Datos preparados: 38772 train, 9694 test\n",
      "Entrenando logistic_regression...\n",
      "Entrenando random_forest...\n",
      "Entrenando gradient_boosting...\n",
      "Entrenando svm...\n",
      "   Usando subconjunto de 10000 muestras para SVM\n",
      "‚úÖ 4 modelos entrenados\n",
      "üìà Evaluaci√≥n completada\n",
      "Validaci√≥n cruzada para logistic_regression...\n",
      "Validaci√≥n cruzada para random_forest...\n",
      "Validaci√≥n cruzada para gradient_boosting...\n",
      "Validaci√≥n cruzada para svm...\n",
      "üîÑ Validaci√≥n cruzada completada\n",
      "üèÜ Mejor modelo: gradient_boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 13:51:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Resultados registrados en MLflow\n",
      "üèÜ Mejor modelo seleccionado: gradient_boosting\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el pipeline completo\n",
    "print(\"üöÄ Ejecutando pipeline completo de clasificaci√≥n...\")\n",
    "pipeline_results = classification_pipeline.run_pipeline(df, target_col='risk_category')\n",
    "\n",
    "# Obtener resultados\n",
    "results = pipeline_results['results']\n",
    "cv_results = pipeline_results['cv_results']\n",
    "trained_models = pipeline_results['trained_models']\n",
    "best_model_name = pipeline_results['best_model']\n",
    "\n",
    "print(f\"üèÜ Mejor modelo seleccionado: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008a2b0-0ecb-484c-891c-ea6f176629ac",
   "metadata": {},
   "source": [
    "## Recopilar m√©tricas de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8484219-c09e-479d-a366-f6b681d99463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recopilar m√©tricas de rendimiento\n",
    "performance_comparison = {}\n",
    "for name, metrics in results.items():\n",
    "    performance_comparison[name] = metrics['f1_weighted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5674c6-5f2d-43b4-b584-8cc00bfa4583",
   "metadata": {},
   "source": [
    "## Ensamblaje de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58258982-f286-4787-8581-6765de0afeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Creando modelos ensemble...\n",
      " Evaluando Voting Classifier...\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"ensemble_classification\"):\n",
    "    mlflow.set_tag(\"model_family\", \"ensemble\")\n",
    "    mlflow.set_tag(\"model_type\", \"classification\")\n",
    "    \n",
    "    # 0. Reconstruir datos COMPLETOS desde cero\n",
    "    X_train, X_test, y_train, y_test = classification_pipeline.prepare_data(df)\n",
    "    X_full = pd.concat([X_train, X_test])\n",
    "    y_full = pd.concat([y_train, y_test])\n",
    "    \n",
    "    # 1. Definir best_models usando los modelos entrenados\n",
    "    best_models = {\n",
    "        'logistic_regression': trained_models['logistic_regression'],\n",
    "        'random_forest': trained_models['random_forest'],\n",
    "        'gradient_boosting': trained_models['gradient_boosting'],\n",
    "        'svm': trained_models['svm']\n",
    "    }\n",
    "    \n",
    "    print(\"üöÄ Creando modelos ensemble...\")\n",
    "    \n",
    "    # 2. Inicializar ensemble\n",
    "    ensemble = AlzheimerEnsemble()\n",
    "    \n",
    "    # 3. Crear ensembles personalizados\n",
    "    voting_clf = ensemble.create_custom_voting_ensemble(best_models)\n",
    "    stacking_clf = ensemble.create_custom_stacking_ensemble(best_models)\n",
    "    \n",
    "    # 4. Evaluar con cross_validate (para m√©tricas consistentes)\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    \n",
    "    print(\" Evaluando Voting Classifier...\")\n",
    "    voting_cv = cross_validate(\n",
    "        voting_clf, X_full, y_full,\n",
    "        cv=3,  # Reducido para mayor velocidad\n",
    "        scoring=['f1_weighted', 'accuracy'],\n",
    "        n_jobs=1\n",
    "    )\n",
    "    \n",
    "    print(\" Evaluando Stacking Classifier...\")\n",
    "    stacking_cv = cross_validate(\n",
    "        stacking_clf, X_full, y_full,\n",
    "        cv=3,  # Reducido para mayor velocidad\n",
    "        scoring=['f1_weighted', 'accuracy'],\n",
    "        n_jobs=1\n",
    "    )\n",
    "    \n",
    "    # 5. Entrenar modelos finales (con todos los datos)\n",
    "    print(\" Entrenando modelos finales...\")\n",
    "    voting_clf.fit(X_full, y_full)\n",
    "    stacking_clf.fit(X_full, y_full)\n",
    "    \n",
    "    # 6. Registrar resultados\n",
    "    mlflow.log_metrics({\n",
    "        'voting_f1_weighted': voting_cv['test_f1_weighted'].mean(),\n",
    "        'voting_accuracy': voting_cv['test_accuracy'].mean(),\n",
    "        'stacking_f1_weighted': stacking_cv['test_f1_weighted'].mean(),\n",
    "        'stacking_accuracy': stacking_cv['test_accuracy'].mean()\n",
    "    })\n",
    "    \n",
    "    mlflow.sklearn.log_model(voting_clf, \"voting_ensemble\")\n",
    "    mlflow.sklearn.log_model(stacking_clf, \"stacking_ensemble\")\n",
    "    \n",
    "    print(f\"\"\" Ensembles creados y registrados!\n",
    "Voting F1: {voting_cv['test_f1_weighted'].mean():.4f}\n",
    "Stacking F1: {stacking_cv['test_f1_weighted'].mean():.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af72724-5d9f-4d2e-8124-82e812e8a222",
   "metadata": {},
   "source": [
    "## An√°lisis de Importancia de Caracter√≠sticas (Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a4ee9-8ab8-4649-ab4c-91be11ec2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de importancia de caracter√≠sticas (para modelos tree-based)\n",
    "print(\"\\nüîç AN√ÅLISIS DE IMPORTANCIA DE FEATURES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Obtener nombres de caracter√≠sticas\n",
    "exclude_cols = ['composite_risk_score', 'risk_category']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "# Combinar importancias de modelos\n",
    "combined_importance = pd.DataFrame()\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    if hasattr(model.named_steps['classifier'], 'feature_importances_'):\n",
    "        importance = model_utils.get_feature_importance(\n",
    "            model.named_steps['classifier'], feature_cols\n",
    "        )\n",
    "        combined_importance[name] = importance.set_index('feature')['importance']\n",
    "\n",
    "if not combined_importance.empty:\n",
    "    combined_importance['Mean_Importance'] = combined_importance.mean(axis=1)\n",
    "    top_features = combined_importance.nlargest(15, 'Mean_Importance')\n",
    "    \n",
    "    # Visualizaci√≥n y guardado de resultados\n",
    "    print(\"üéØ Top 15 Features m√°s importantes:\")\n",
    "    print(top_features[['Mean_Importance']].round(4))\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features['Mean_Importance'].plot(kind='barh', color='lightgreen')\n",
    "    plt.title('Top 15 Features - Importancia Promedio')\n",
    "    plt.xlabel('Importancia Promedio')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6804bd6-be0d-44bb-bb05-9d1dc2371052",
   "metadata": {},
   "source": [
    "## Comparaci√≥n Final de Modelos (agregando los ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6eab4-c8e0-4c37-aacb-1d58c20407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARACI√ìN FINAL DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': model, 'F1_Score_Weighted': score} \n",
    "    for model, score in performance_comparison.items()\n",
    "]).sort_values('F1_Score_Weighted', ascending=False)\n",
    "\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualizaci√≥n de comparaci√≥n\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(comparison_df['Model'], comparison_df['F1_Score_Weighted'], \n",
    "               color='lightcoral', alpha=0.8)\n",
    "plt.title('Comparaci√≥n de Rendimiento - Modelos de Clasificaci√≥n')\n",
    "plt.xlabel('Modelo')\n",
    "plt.ylabel('F1-Score Weighted')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for bar, score in zip(bars, comparison_df['F1_Score_Weighted']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "             f'{score:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615f8b8-33da-4b09-a4a6-f4dfea59d99d",
   "metadata": {},
   "source": [
    "## Resumen final y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b284bf1-eae6-4718-b99d-f53704508621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final y recomendaciones\n",
    "best_model = comparison_df.iloc[0]['Model']\n",
    "best_score = comparison_df.iloc[0]['F1_Score_Weighted']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ RESUMEN FINAL - MODELOS DE CLASIFICACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üèÜ Mejor modelo: {best_model}\")\n",
    "print(f\"üìä F1-Score Weighted: {best_score:.4f}\")\n",
    "print(f\"üìà Mejora sobre baseline: {((best_score - lr_performance) / lr_performance * 100):.1f}%\")\n",
    "print(f\"‚öñÔ∏è Desbalanceamiento de clases: {imbalance_ratio:.2f}\")\n",
    "print(f\"üéØ Total de modelos entrenados: {len(performance_comparison)}\")\n",
    "\n",
    "print(\"\\nüí° RECOMENDACIONES:\")\n",
    "if best_score > 0.85:\n",
    "    print(\"‚úÖ Excelente rendimiento alcanzado\")\n",
    "elif best_score > 0.75:\n",
    "    print(\"‚ö†Ô∏è Buen rendimiento, considerar optimizaci√≥n en Fase 5\")\n",
    "else:\n",
    "    print(\"‚ùå Rendimiento bajo, requiere optimizaci√≥n en Fase 5\")\n",
    "\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"‚öñÔ∏è Considerar t√©cnicas de balanceamiento adicionales\")\n",
    "\n",
    "print(\"\\nüîÑ Listo para Fase 5: Evaluaci√≥n y Optimizaci√≥n\")\n",
    "print(\"üìÅ Todos los modelos guardados en MLflow\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc956bf4-f1f0-4459-a108-b25b5866412f",
   "metadata": {},
   "source": [
    "## Guardado de Archivos Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1d0b5-b90c-4238-8393-7ea842323335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar m√©tricas finales\n",
    "final_metrics = {\n",
    "    'best_model': best_model,\n",
    "    'best_f1_score': best_score,\n",
    "    'baseline_f1_score': lr_performance,\n",
    "    'improvement_percentage': (best_score - lr_performance) / lr_performance * 100,\n",
    "    'models_trained': len(performance_comparison),\n",
    "    'imbalance_ratio': imbalance_ratio,\n",
    "    'training_samples': len(X),\n",
    "    'features_used': len(feature_cols)\n",
    "}\n",
    "\n",
    "# Guardar en archivo\n",
    "pd.Series(final_metrics).to_csv('../reports/model_results/classification_summary.csv')\n",
    "print(\"üìÅ M√©tricas guardadas en: ../reports/model_results/classification_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea49671-6862-465d-b167-7d9376375a4d",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd92a04-76e6-4e89-a049-50109034d6e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683824d-8d44-4159-bfde-39748ef333a3",
   "metadata": {},
   "source": [
    "__Abraham Tartalos__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
