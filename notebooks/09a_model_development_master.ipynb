{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef495183-83d0-496c-855c-0ceab5183d2e",
   "metadata": {},
   "source": [
    "# üìäNOTEBOOK MASTER DE DESARROLLO DE MODELO - COORDINADOR PRINCIPAL\n",
    "## Monitorizaci√≥n y Prevenci√≥n Multimodal de Alzheimer - Fase 4\n",
    " \n",
    "**Objetivo**: Orquestar el desarrollo completo de modelos para predicci√≥n de riesgo de Alzheimer\n",
    " \n",
    "### üéØ Objetivos de la Fase 4:\n",
    " - **Regresi√≥n**: Predicci√≥n del `composite_risk_score` (continuo 0-1)\n",
    " - **Clasificaci√≥n**: Predicci√≥n de `risk_category` (Low/Moderate/High)\n",
    " - **An√°lisis Temporal**: Modelos para evoluci√≥n longitudinal\n",
    " - **Estratificaci√≥n**: Segmentaci√≥n de pacientes por riesgo\n",
    " \n",
    "### üìã Pipeline de Desarrollo:\n",
    "1. **Configuraci√≥n del entorno ML** (MLflow, validaci√≥n cruzada)\n",
    "2. **Preparaci√≥n de datos** (splits, validaci√≥n)\n",
    "3. **Modelos de Regresi√≥n** ‚Üí `09b_regression_models.ipynb`\n",
    "4. **Modelos de Clasificaci√≥n** ‚Üí `09c_classification_models.ipynb`\n",
    "5. **An√°lisis Temporal** ‚Üí `09d_temporal_analysis.ipynb`\n",
    "6. **Estratificaci√≥n de Riesgo** ‚Üí `09e_risk_stratification.ipynb`\n",
    "7. **Evaluaci√≥n Final y Selecci√≥n**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8229858-2655-4641-acdc-66fc54b375e3",
   "metadata": {},
   "source": [
    "## Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3817d22-1478-45af-8808-5622077d2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# MLflow para tracking\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Utilities\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('../scripts/modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2138b8fa-ab40-4908-a4e0-695b12e0e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Fase 4: Desarrollo de Modelos\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Iniciando Fase 4: Desarrollo de Modelos\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ad125-efb1-40c7-ae79-cf2a9092c223",
   "metadata": {},
   "source": [
    "## üìÅ CONFIGURACI√ìN DE RUTAS Y CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9f5044-b66f-419a-b885-16bd2f341eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Configurando rutas y cargando datos...\n",
      "üìä Cargando dataset final...\n",
      "üìã Cargando metadatos de feature engineering...\n",
      "‚úÖ Dataset cargado: (48466, 189)\n",
      "‚úÖ Features seleccionadas: 192\n",
      "‚úÖ Registros v√°lidos: 48466\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÅ Configurando rutas y cargando datos...\")\n",
    "\n",
    "# Rutas de archivos\n",
    "DATA_PATH = '../data/processed/features/'\n",
    "METADATA_PATH = '../data/processed/features/'\n",
    "MODELS_PATH = '../models/'\n",
    "RESULTS_PATH = '../reports/modeling/'\n",
    "\n",
    "# Crear directorios si no existen\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "# Cargar dataset final procesado\n",
    "print(\"üìä Cargando dataset final...\")\n",
    "df_final = pd.read_csv(f'{DATA_PATH}alzheimer_features_selected_20250605.csv')\n",
    "\n",
    "# Cargar metadatos de feature engineering\n",
    "print(\"üìã Cargando metadatos de feature engineering...\")\n",
    "with open('../data/processed/features/feature_engineering_metadata_20250605.json', 'r') as f:\n",
    "    fe_metadata = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Dataset cargado: {df_final.shape}\")\n",
    "print(f\"‚úÖ Features seleccionadas: {len(fe_metadata['selected_features'])}\")\n",
    "print(f\"‚úÖ Registros v√°lidos: {df_final['composite_risk_score'].notna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb6db0-6bee-452d-ae44-c4bd834c271f",
   "metadata": {},
   "source": [
    "## üîß CONFIGURACI√ìN DE MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee917622-78bd-442e-9233-b2d213ed774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Configurando MLflow para tracking de experimentos...\n",
      "‚úÖ Experimento creado: Alzheimer_Multimodal_Monitoring_Phase4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Configurando MLflow para tracking de experimentos...\")\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "experiment_name = \"Alzheimer_Multimodal_Monitoring_Phase4\"\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    print(f\"‚úÖ Experimento creado: {experiment_name}\")\n",
    "except:\n",
    "    experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    print(f\"‚úÖ Experimento existente: {experiment_name}\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Cliente MLflow para gesti√≥n avanzada\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b422f89-8b69-49cc-b404-9412d0a1d87e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üìä AN√ÅLISIS PRELIMINAR DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ec6d8e-cb7a-4942-a9e2-a750ee193fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Realizando an√°lisis preliminar del dataset...\n",
      "üîç INFORMACI√ìN B√ÅSICA DEL DATASET:\n",
      "  ‚Ä¢ Forma del dataset: (48466, 189)\n",
      "  ‚Ä¢ Registros √∫nicos: 48198\n",
      "  ‚Ä¢ Memoria utilizada: 92.6 MB\n",
      "\n",
      "üéØ VARIABLES OBJETIVO:\n",
      "  ‚Ä¢ Continua: composite_risk_score\n",
      "  ‚Ä¢ Categ√≥rica: risk_category\n",
      "\n",
      "üìà DISTRIBUCI√ìN - COMPOSITE_RISK_SCORE:\n",
      "  ‚Ä¢ count: 48466.0000\n",
      "  ‚Ä¢ mean: 0.3671\n",
      "  ‚Ä¢ std: 0.2128\n",
      "  ‚Ä¢ min: 0.0000\n",
      "  ‚Ä¢ 25%: 0.1489\n",
      "  ‚Ä¢ 50%: 0.3631\n",
      "  ‚Ä¢ 75%: 0.5714\n",
      "  ‚Ä¢ max: 0.9286\n",
      "\n",
      "üìä DISTRIBUCI√ìN - RISK_CATEGORY:\n",
      "  ‚Ä¢ Low: 22,501 (46.4%)\n",
      "  ‚Ä¢ Moderate: 22,345 (46.1%)\n",
      "  ‚Ä¢ High: 3,620 (7.5%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä Realizando an√°lisis preliminar del dataset...\")\n",
    "\n",
    "# Informaci√≥n b√°sica\n",
    "print(\"üîç INFORMACI√ìN B√ÅSICA DEL DATASET:\")\n",
    "print(f\"  ‚Ä¢ Forma del dataset: {df_final.shape}\")\n",
    "print(f\"  ‚Ä¢ Registros √∫nicos: {df_final.drop_duplicates().shape[0]}\")\n",
    "print(f\"  ‚Ä¢ Memoria utilizada: {df_final.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Variables objetivo\n",
    "target_continuous = 'composite_risk_score'\n",
    "target_categorical = 'risk_category'\n",
    "\n",
    "print(f\"\\nüéØ VARIABLES OBJETIVO:\")\n",
    "print(f\"  ‚Ä¢ Continua: {target_continuous}\")\n",
    "print(f\"  ‚Ä¢ Categ√≥rica: {target_categorical}\")\n",
    "\n",
    "# Distribuci√≥n de la variable objetivo continua\n",
    "print(f\"\\nüìà DISTRIBUCI√ìN - {target_continuous.upper()}:\")\n",
    "target_stats = df_final[target_continuous].describe()\n",
    "for stat, value in target_stats.items():\n",
    "    print(f\"  ‚Ä¢ {stat}: {value:.4f}\")\n",
    "\n",
    "# Distribuci√≥n de la variable objetivo categ√≥rica\n",
    "print(f\"\\nüìä DISTRIBUCI√ìN - {target_categorical.upper()}:\")\n",
    "risk_dist = df_final[target_categorical].value_counts()\n",
    "risk_pct = df_final[target_categorical].value_counts(normalize=True) * 100\n",
    "for category in risk_dist.index:\n",
    "    print(f\"  ‚Ä¢ {category}: {risk_dist[category]:,} ({risk_pct[category]:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f4617e-089f-4aab-921b-7e9264c762ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üßπ PREPARACI√ìN DE DATOS PARA MODELADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca202bbb-4f3e-4053-a8da-6fed22b3a64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßπ Preparando datos para modelado...\n",
      "‚úÖ Features para modelado: 178\n",
      "\n",
      "‚ö†Ô∏è  VALORES FALTANTES DETECTADOS:\n",
      "  ‚Ä¢ DXAD: 36,053 (74.4%)\n",
      "  ‚Ä¢ DXNORM: 36,053 (74.4%)\n",
      "  ‚Ä¢ CDRSB_CHANGE_ANNUAL_normalized: 28,462 (58.7%)\n",
      "  ‚Ä¢ CDRSB_CHANGE_normalized: 28,447 (58.7%)\n",
      "  ‚Ä¢ APTESTDT_year: 27,450 (56.6%)\n",
      "  ‚Ä¢ USERDATE_day: 27,450 (56.6%)\n",
      "  ‚Ä¢ APTESTDT_years_ago: 27,450 (56.6%)\n",
      "  ‚Ä¢ USERDATE_years_ago: 27,450 (56.6%)\n",
      "  ‚Ä¢ USERDATE_year: 27,450 (56.6%)\n",
      "  ‚Ä¢ SITEID: 27,450 (56.6%)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'F'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Estrategia de imputaci√≥n simple para el an√°lisis inicial\u001b[39;00m\n\u001b[0;32m     28\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m X_imputed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     30\u001b[0m X \u001b[38;5;241m=\u001b[39m X_imputed\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Valores faltantes imputados con mediana\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    904\u001b[0m             (\n\u001b[0;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    914\u001b[0m         )\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\sklearn\\impute\\_base.py:434\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\Programas\\miniconda3\\envs\\ea-env-py310\\lib\\site-packages\\sklearn\\impute\\_base.py:361\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[0;32m    356\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    358\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[0;32m    359\u001b[0m         )\n\u001b[0;32m    360\u001b[0m     )\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'F'"
     ]
    }
   ],
   "source": [
    "print(\"\\nüßπ Preparando datos para modelado...\")\n",
    "\n",
    "# Identificar features num√©ricas (excluyendo targets)\n",
    "features_to_exclude = [target_continuous, target_categorical, 'subject_id', 'ID', 'RID', \n",
    "                      'mapped_rid', 'subject_id_clinical', 'subject_id_genetics', \n",
    "                      'subject_id_activity', 'PTID_apoe', 'RID_genetics']\n",
    "\n",
    "# Features para modeling\n",
    "feature_cols = [col for col in df_final.columns if col not in features_to_exclude]\n",
    "print(f\"‚úÖ Features para modelado: {len(feature_cols)}\")\n",
    "\n",
    "# Preparar matrices de features y targets\n",
    "X = df_final[feature_cols].copy()\n",
    "y_continuous = df_final[target_continuous].copy()\n",
    "y_categorical = df_final[target_categorical].copy()\n",
    "\n",
    "# Identificar y manejar valores faltantes\n",
    "missing_info = X.isnull().sum()\n",
    "missing_cols = missing_info[missing_info > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(missing_cols) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  VALORES FALTANTES DETECTADOS:\")\n",
    "    for col, missing_count in missing_cols.head(10).items():\n",
    "        missing_pct = (missing_count / len(X)) * 100\n",
    "        print(f\"  ‚Ä¢ {col}: {missing_count:,} ({missing_pct:.1f}%)\")\n",
    "    \n",
    "    # Estrategia de imputaci√≥n simple para el an√°lisis inicial\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
    "    X = X_imputed\n",
    "    print(\"‚úÖ Valores faltantes imputados con mediana\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset preparado: {X.shape}\")\n",
    "print(f\"‚úÖ Targets v√°lidos: {len(y_continuous.dropna())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72a4f5-5bff-4d97-93c2-6b17720ce92e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üîÑ CONFIGURACI√ìN DE VALIDACI√ìN CRUZADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294ae9b-4073-480d-9372-84b318f30b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Configurando estrategias de validaci√≥n...\")\n",
    "\n",
    "# Par√°metros de validaci√≥n\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Split estratificado basado en risk_category\n",
    "print(\"üìä Realizando split estratificado...\")\n",
    "X_train, X_test, y_train_cont, y_test_cont, y_train_cat, y_test_cat = train_test_split(\n",
    "    X, y_continuous, y_categorical,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=y_categorical,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training set: {X_train.shape}\")\n",
    "print(f\"‚úÖ Test set: {X_test.shape}\")\n",
    "\n",
    "# Validaci√≥n cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"‚úÖ Validaci√≥n cruzada: {N_SPLITS} folds estratificados\")\n",
    "\n",
    "# Verificar distribuci√≥n en splits\n",
    "print(f\"\\nüìä DISTRIBUCI√ìN EN SPLITS:\")\n",
    "print(\"Training set:\")\n",
    "train_dist = y_train_cat.value_counts(normalize=True) * 100\n",
    "for category, pct in train_dist.items():\n",
    "    print(f\"  ‚Ä¢ {category}: {pct:.1f}%\")\n",
    "\n",
    "print(\"Test set:\")\n",
    "test_dist = y_test_cat.value_counts(normalize=True) * 100\n",
    "for category, pct in test_dist.items():\n",
    "    print(f\"  ‚Ä¢ {category}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03fde1f-1cc5-4a2c-84aa-f4d5612fe706",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üéØ CONFIGURACI√ìN DE ALGORITMOS Y PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5e218-6a4e-4bce-aae5-03e904feaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ Configurando algoritmos para desarrollo...\")\n",
    "\n",
    "# Algoritmos para regresi√≥n (composite_risk_score)\n",
    "REGRESSION_ALGORITHMS = {\n",
    "    'RandomForest': {\n",
    "        'estimator': 'RandomForestRegressor',\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 15, 20, None],\n",
    "            'min_samples_split': [5, 10],\n",
    "            'min_samples_leaf': [2, 4],\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        },\n",
    "        'priority': 'high'\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'estimator': 'XGBRegressor',\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [6, 8, 10],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        },\n",
    "        'priority': 'high'\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'estimator': 'LGBMRegressor',\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [6, 8],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'num_leaves': [31, 63]\n",
    "        },\n",
    "        'priority': 'medium'\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'estimator': 'ElasticNet',\n",
    "        'params': {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0],\n",
    "            'l1_ratio': [0.1, 0.5, 0.7, 0.9]\n",
    "        },\n",
    "        'priority': 'baseline'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Algoritmos para clasificaci√≥n (risk_category)\n",
    "CLASSIFICATION_ALGORITHMS = {\n",
    "    'RandomForest': {\n",
    "        'estimator': 'RandomForestClassifier',\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 15, 20],\n",
    "            'min_samples_split': [5, 10],\n",
    "            'class_weight': ['balanced', None]\n",
    "        },\n",
    "        'priority': 'high'\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'estimator': 'XGBClassifier',\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [6, 8],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'scale_pos_weight': [1, 2, 3]\n",
    "        },\n",
    "        'priority': 'high'\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'estimator': 'LogisticRegression',\n",
    "        'params': {\n",
    "            'C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        },\n",
    "        'priority': 'baseline'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Algoritmos de regresi√≥n configurados: {len(REGRESSION_ALGORITHMS)}\")\n",
    "print(f\"‚úÖ Algoritmos de clasificaci√≥n configurados: {len(CLASSIFICATION_ALGORITHMS)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccfff1c-8cc3-4229-bfcd-5b8ea10deaa9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üìä CONFIGURACI√ìN DE M√âTRICAS DE EVALUACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800411d-3963-453b-bb73-bde2e2cbef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Configurando m√©tricas de evaluaci√≥n...\")\n",
    "\n",
    "# M√©tricas para regresi√≥n\n",
    "REGRESSION_METRICS = {\n",
    "    'primary': ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],\n",
    "    'secondary': ['neg_root_mean_squared_error'],\n",
    "    'clinical': ['mean_absolute_percentage_error']\n",
    "}\n",
    "\n",
    "# M√©tricas para clasificaci√≥n\n",
    "CLASSIFICATION_METRICS = {\n",
    "    'primary': ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
    "    'secondary': ['roc_auc_ovr', 'precision_weighted', 'recall_weighted'],\n",
    "    'clinical': ['balanced_accuracy']\n",
    "}\n",
    "\n",
    "print(\"‚úÖ M√©tricas de regresi√≥n configuradas:\")\n",
    "for metric_type, metrics in REGRESSION_METRICS.items():\n",
    "    print(f\"  ‚Ä¢ {metric_type}: {', '.join(metrics)}\")\n",
    "\n",
    "print(\"‚úÖ M√©tricas de clasificaci√≥n configuradas:\")\n",
    "for metric_type, metrics in CLASSIFICATION_METRICS.items():\n",
    "    print(f\"  ‚Ä¢ {metric_type}: {', '.join(metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ba3b3-1c37-4b9d-863f-30c7c5c19c88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üíæ GUARDADO DE CONFIGURACI√ìN Y METADATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c872f5-ede7-4ec1-93fe-031480521c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüíæ Guardando configuraci√≥n de modelado...\")\n",
    "\n",
    "# Crear metadatos de la fase de modelado\n",
    "modeling_metadata = {\n",
    "    'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S'),\n",
    "    'phase': 'model_development',\n",
    "    'dataset_info': {\n",
    "        'shape': df_final.shape,\n",
    "        'features_count': len(feature_cols),\n",
    "        'training_samples': len(X_train),\n",
    "        'test_samples': len(X_test)\n",
    "    },\n",
    "    'targets': {\n",
    "        'continuous': target_continuous,\n",
    "        'categorical': target_categorical\n",
    "    },\n",
    "    'validation_config': {\n",
    "        'test_size': TEST_SIZE,\n",
    "        'cv_folds': N_SPLITS,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'stratification': 'risk_category'\n",
    "    },\n",
    "    'algorithms': {\n",
    "        'regression': list(REGRESSION_ALGORITHMS.keys()),\n",
    "        'classification': list(CLASSIFICATION_ALGORITHMS.keys())\n",
    "    },\n",
    "    'feature_engineering_source': fe_metadata['timestamp']\n",
    "}\n",
    "\n",
    "# Guardar metadatos\n",
    "metadata_file = f'{METADATA_PATH}modeling_metadata_{modeling_metadata[\"timestamp\"]}.json'\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(modeling_metadata, f, indent=2)\n",
    "\n",
    "# Guardar splits de datos para consistencia\n",
    "print(\"üíæ Guardando splits de datos...\")\n",
    "train_indices = pd.DataFrame({'index': X_train.index})\n",
    "test_indices = pd.DataFrame({'index': X_test.index})\n",
    "\n",
    "train_indices.to_csv(f'{DATA_PATH}train_indices.csv', index=False)\n",
    "test_indices.to_csv(f'{DATA_PATH}test_indices.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Metadatos guardados: {metadata_file}\")\n",
    "print(f\"‚úÖ Splits guardados en {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8fd72a-4bb7-4ba3-b4d9-a679dadc0289",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üéØ VISUALIZACI√ìN DE DISTRIBUCIONES DE TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f63747-f714-437f-8c0f-b9c69b1995c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ Creando visualizaciones preliminares...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('üìä An√°lisis de Variables Objetivo - Alzheimer Risk Prediction', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribuci√≥n del score continuo\n",
    "axes[0, 0].hist(y_continuous.dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].axvline(y_continuous.mean(), color='red', linestyle='--', \n",
    "                   label=f'Media: {y_continuous.mean():.3f}')\n",
    "axes[0, 0].set_title('Distribuci√≥n del Composite Risk Score')\n",
    "axes[0, 0].set_xlabel('Risk Score')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Distribuci√≥n categ√≥rica\n",
    "risk_counts = y_categorical.value_counts()\n",
    "colors = ['green', 'orange', 'red']\n",
    "axes[0, 1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%',\n",
    "               colors=colors, startangle=90)\n",
    "axes[0, 1].set_title('Distribuci√≥n de Categor√≠as de Riesgo')\n",
    "\n",
    "# 3. Boxplot por categor√≠a\n",
    "df_plot = pd.DataFrame({\n",
    "    'risk_score': y_continuous,\n",
    "    'risk_category': y_categorical\n",
    "}).dropna()\n",
    "\n",
    "sns.boxplot(data=df_plot, x='risk_category', y='risk_score', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Risk Score por Categor√≠a')\n",
    "axes[1, 0].set_xlabel('Categor√≠a de Riesgo')\n",
    "axes[1, 0].set_ylabel('Composite Risk Score')\n",
    "\n",
    "# 4. Distribuci√≥n en train/test\n",
    "split_data = pd.DataFrame({\n",
    "    'split': ['Train'] * len(y_train_cat) + ['Test'] * len(y_test_cat),\n",
    "    'category': list(y_train_cat) + list(y_test_cat)\n",
    "})\n",
    "\n",
    "split_counts = split_data.groupby(['split', 'category']).size().unstack(fill_value=0)\n",
    "split_counts.plot(kind='bar', ax=axes[1, 1], color=colors)\n",
    "axes[1, 1].set_title('Distribuci√≥n Train/Test por Categor√≠a')\n",
    "axes[1, 1].set_xlabel('Split')\n",
    "axes[1, 1].set_ylabel('N√∫mero de Muestras')\n",
    "axes[1, 1].legend(title='Risk Category')\n",
    "axes[1, 1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_PATH}target_distributions_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e8177-1b0e-49c0-b1a4-31f26658304a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üöÄ PLAN DE EJECUCI√ìN DE NOTEBOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a681971-5530-4c92-8eb2-3f6c5f946fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ PLAN DE EJECUCI√ìN - FASE 4: DESARROLLO DE MODELOS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "execution_plan = {\n",
    "    '04b_regression_models.ipynb': {\n",
    "        'objetivo': 'Predicci√≥n del composite_risk_score (regresi√≥n)',\n",
    "        'algoritmos': list(REGRESSION_ALGORITHMS.keys()),\n",
    "        'prioridad': 'Alta',\n",
    "        'tiempo_estimado': '2-3 horas',\n",
    "        'dependencias': ['Datos preparados', 'MLflow configurado']\n",
    "    },\n",
    "    '04c_classification_models.ipynb': {\n",
    "        'objetivo': 'Predicci√≥n de risk_category (clasificaci√≥n)',\n",
    "        'algoritmos': list(CLASSIFICATION_ALGORITHMS.keys()),\n",
    "        'prioridad': 'Alta',\n",
    "        'tiempo_estimado': '2-3 horas',\n",
    "        'dependencias': ['Regresi√≥n completada']\n",
    "    },\n",
    "    '04d_temporal_analysis.ipynb': {\n",
    "        'objetivo': 'An√°lisis de series temporales y evoluci√≥n',\n",
    "        'algoritmos': ['LSTM', 'ARIMA', 'Time Series RF'],\n",
    "        'prioridad': 'Media',\n",
    "        'tiempo_estimado': '3-4 horas',\n",
    "        'dependencias': ['Modelos base completados']\n",
    "    },\n",
    "    '04e_risk_stratification.ipynb': {\n",
    "        'objetivo': 'Estratificaci√≥n y segmentaci√≥n de pacientes',\n",
    "        'algoritmos': ['Clustering', 'Survival Analysis'],\n",
    "        'prioridad': 'Media',\n",
    "        'tiempo_estimado': '2 horas',\n",
    "        'dependencias': ['An√°lisis temporal completado']\n",
    "    }\n",
    "}\n",
    "\n",
    "for notebook, info in execution_plan.items():\n",
    "    print(f\"\\nüìì {notebook}\")\n",
    "    print(f\"   üéØ Objetivo: {info['objetivo']}\")\n",
    "    print(f\"   ü§ñ Algoritmos: {', '.join(info['algoritmos'])}\")\n",
    "    print(f\"   ‚≠ê Prioridad: {info['prioridad']}\")\n",
    "    print(f\"   ‚è±Ô∏è  Tiempo estimado: {info['tiempo_estimado']}\")\n",
    "    print(f\"   üìã Dependencias: {', '.join(info['dependencias'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66626583-3399-4087-b229-20ba3112db2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ‚úÖ VERIFICACI√ìN FINAL Y SIGUIENTE PASO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740320e-ab50-41ce-9268-91001be4a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"‚úÖ CONFIGURACI√ìN COMPLETADA - FASE 4: DESARROLLO DE MODELOS\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Verificaciones finales\n",
    "checks = {\n",
    "    'Datos cargados correctamente': df_final.shape[0] > 0,\n",
    "    'Features seleccionadas': len(feature_cols) > 0,\n",
    "    'Splits realizados': len(X_train) > 0 and len(X_test) > 0,\n",
    "    'MLflow configurado': mlflow.get_experiment_by_name(experiment_name) is not None,\n",
    "    'Targets v√°lidos': y_continuous.notna().sum() > 0,\n",
    "    'Metadatos guardados': os.path.exists(metadata_file)\n",
    "}\n",
    "\n",
    "print(\"\\nüîç VERIFICACIONES FINALES:\")\n",
    "for check, status in checks.items():\n",
    "    status_symbol = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"   {status_symbol} {check}\")\n",
    "\n",
    "# Resumen de preparaci√≥n\n",
    "print(f\"\\nüìä RESUMEN DE PREPARACI√ìN:\")\n",
    "print(f\"   ‚Ä¢ Dataset: {df_final.shape[0]:,} registros, {len(feature_cols)} features\")\n",
    "print(f\"   ‚Ä¢ Training: {len(X_train):,} muestras\")\n",
    "print(f\"   ‚Ä¢ Testing: {len(X_test):,} muestras\")\n",
    "print(f\"   ‚Ä¢ Target continuo: {target_continuous}\")\n",
    "print(f\"   ‚Ä¢ Target categ√≥rico: {target_categorical}\")\n",
    "print(f\"   ‚Ä¢ MLflow experiment: {experiment_name}\")\n",
    "\n",
    "print(f\"\\nüéØ SIGUIENTE PASO:\")\n",
    "print(f\"   ‚û°Ô∏è  Ejecutar: 04b_regression_models.ipynb\")\n",
    "print(f\"   üéØ Objetivo: Desarrollar modelos de regresi√≥n para composite_risk_score\")\n",
    "print(f\"   üìä Algoritmos prioritarios: Random Forest, XGBoost\")\n",
    "\n",
    "print(\"\\nüöÄ ¬°Fase 4 lista para comenzar el desarrollo de modelos!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6cbec2-c616-4efe-a066-8a022affa92c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üìù LOG DE CONFIGURACI√ìN PARA MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59478864-fa06-4ecf-9534-52767b5514a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìù Registrando configuraci√≥n inicial en MLflow...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Phase4_Setup_Configuration\"):\n",
    "    # Log de par√°metros de configuraci√≥n\n",
    "    mlflow.log_param(\"phase\", \"model_development_setup\")\n",
    "    mlflow.log_param(\"dataset_shape\", f\"{df_final.shape[0]}x{df_final.shape[1]}\")\n",
    "    mlflow.log_param(\"features_count\", len(feature_cols))\n",
    "    mlflow.log_param(\"train_samples\", len(X_train))\n",
    "    mlflow.log_param(\"test_samples\", len(X_test))\n",
    "    mlflow.log_param(\"cv_folds\", N_SPLITS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    \n",
    "    # Log de distribuci√≥n de targets\n",
    "    for category, count in y_categorical.value_counts().items():\n",
    "        mlflow.log_metric(f\"target_distribution_{category}\", count)\n",
    "    \n",
    "    mlflow.log_metric(\"target_mean\", y_continuous.mean())\n",
    "    mlflow.log_metric(\"target_std\", y_continuous.std())\n",
    "    \n",
    "    # Guardar artefactos\n",
    "    mlflow.log_artifact(metadata_file, \"metadata\")\n",
    "    mlflow.log_artifact(f'{RESULTS_PATH}target_distributions_analysis.png', \"visualizations\")\n",
    "    \n",
    "    # Tags\n",
    "    mlflow.set_tag(\"project\", \"Alzheimer_Risk_Prediction\")\n",
    "    mlflow.set_tag(\"phase\", \"4_model_development\")\n",
    "    mlflow.set_tag(\"setup_status\", \"completed\")\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n registrada en MLflow\")\n",
    "print(\"\\nüéâ ¬°Master Coordinator completado exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e91dc8-031f-4db7-9065-e857fba6b139",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91530f47-be01-43e8-93ec-a6d2aa63ec69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a5edc-6762-4e14-996d-8faa3ce460e9",
   "metadata": {},
   "source": [
    "__Abraham Tartalos__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
