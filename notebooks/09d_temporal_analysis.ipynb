{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63d2c79-2599-4a77-b1d0-c8b6d3423b7b",
   "metadata": {},
   "source": [
    "# 04d - Análisis Temporal y Modelos de Series de Tiempo\n",
    "\n",
    "**Objetivo:** Desarrollar modelos temporales para analizar la evolución del riesgo de Alzheimer\n",
    " \n",
    "**Enfoque**: \n",
    "- Series temporales para predicción de composite_risk_score\n",
    "- Análisis de tendencias en biomarcadores\n",
    "- Patrones temporales en actividad/sueño\n",
    "- Modelos de supervivencia para progresión del riesgo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d262215-a3b0-4869-99f6-39fd7a8c357e",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8239179-2859-4bbe-a07d-3980d8e18326",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2c002-a65d-4b3a-a591-4d8837a6b23a",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cd4dd-c990-4b1b-8001-5df357e0c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23342975-7b35-4681-8910-9fe585eddd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración MLflow\n",
    "mlflow.set_experiment(\"temporal_analysis_alzheimer\")\n",
    "\n",
    "print(\"🕒 Iniciando Análisis Temporal - Monitorización Multimodal Alzheimer\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b1068-c410-4ef7-9803-203c0109384f",
   "metadata": {},
   "source": [
    "## 1. Carga y Preparación de Datos Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2fe01-fc38-4da6-a53e-2bb87b7cfe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_temporal_data():\n",
    "    \"\"\"Carga datos con estructura temporal simulada\"\"\"\n",
    "    # Cargar datos principales\n",
    "    try:\n",
    "        df = pd.read_csv('../data/processed/fe_master_dataset.csv')\n",
    "        print(f\"✅ Dataset cargado: {df.shape}\")\n",
    "    except:\n",
    "        print(\"⚠️  Generando datos sintéticos para demostración\")\n",
    "        # Datos sintéticos basados en el análisis previo\n",
    "        np.random.seed(42)\n",
    "        n_subjects = 1000\n",
    "        n_timepoints = 5  # 5 visitas por sujeto\n",
    "        \n",
    "        data = []\n",
    "        for subject_id in range(n_subjects):\n",
    "            base_risk = np.random.uniform(0.1, 0.8)\n",
    "            base_age = np.random.uniform(60, 85)\n",
    "            apoe_status = np.random.choice([0, 1], p=[0.7, 0.3])\n",
    "            \n",
    "            for visit in range(n_timepoints):\n",
    "                # Simular progresión temporal\n",
    "                time_factor = visit * 0.1\n",
    "                noise = np.random.normal(0, 0.05)\n",
    "                \n",
    "                row = {\n",
    "                    'subject_id': f'SUBJ_{subject_id:04d}',\n",
    "                    'visit_number': visit + 1,\n",
    "                    'months_from_baseline': visit * 6,  # Visitas cada 6 meses\n",
    "                    'composite_risk_score': np.clip(base_risk + time_factor + noise, 0, 1),\n",
    "                    'age_standardized': base_age + visit * 0.5,\n",
    "                    'APOE_e4_present': apoe_status,\n",
    "                    'biomarker_risk_score': np.clip(base_risk * 1.2 + time_factor + noise, 0, 1),\n",
    "                    'sleep_minutes_mean': np.random.normal(420 - visit * 10, 30),\n",
    "                    'sleep_disruptions_mean': np.random.poisson(2 + visit),\n",
    "                    'steps_mean': np.random.normal(8000 - visit * 200, 1000),\n",
    "                    'CDRSB_LOG': np.random.exponential(0.5 + visit * 0.1),\n",
    "                    'ABETA42': np.random.normal(200 - visit * 5, 20),\n",
    "                    'tau_pathology_score': np.random.uniform(0, 1) + visit * 0.05\n",
    "                }\n",
    "                data.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        print(f\"✅ Datos sintéticos generados: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_temporal = load_temporal_data()\n",
    "\n",
    "# Información básica del dataset temporal\n",
    "print(f\"\\n📊 Información del Dataset Temporal:\")\n",
    "print(f\"   Sujetos únicos: {df_temporal['subject_id'].nunique() if 'subject_id' in df_temporal.columns else 'N/A'}\")\n",
    "print(f\"   Rango temporal: {df_temporal['months_from_baseline'].min() if 'months_from_baseline' in df_temporal.columns else 'N/A'} - {df_temporal['months_from_baseline'].max() if 'months_from_baseline' in df_temporal.columns else 'N/A'} meses\")\n",
    "print(f\"   Variables temporales detectadas: {len([col for col in df_temporal.columns if any(temp in col.lower() for temp in ['mean', 'std', 'min', 'max'])])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9750c-b281-41c3-9421-3fe1f16022f2",
   "metadata": {},
   "source": [
    "## 2. Análisis de Patrones Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49808095-3a58-4f78-b098-dce556bd646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_patterns(df):\n",
    "    \"\"\"Analiza patrones temporales en las variables clave\"\"\"\n",
    "    \n",
    "    print(\"🔍 Analizando Patrones Temporales...\")\n",
    "    \n",
    "    # Variables clave para análisis temporal\n",
    "    temporal_vars = [\n",
    "        'composite_risk_score', 'biomarker_risk_score', 'sleep_minutes_mean',\n",
    "        'sleep_disruptions_mean', 'steps_mean', 'CDRSB_LOG', 'ABETA42', 'tau_pathology_score'\n",
    "    ]\n",
    "    \n",
    "    # Filtrar variables que existen en el dataset\n",
    "    available_vars = [var for var in temporal_vars if var in df.columns]\n",
    "    \n",
    "    if not available_vars:\n",
    "        print(\"⚠️  No se encontraron variables temporales específicas\")\n",
    "        # Usar las primeras 8 variables numéricas\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        available_vars = numeric_cols[:8].tolist()\n",
    "    \n",
    "    print(f\"   Variables analizadas: {len(available_vars)}\")\n",
    "    \n",
    "    # Calcular tendencias por sujeto (si hay estructura temporal)\n",
    "    trends_data = {}\n",
    "    \n",
    "    if 'subject_id' in df.columns and 'months_from_baseline' in df.columns:\n",
    "        for var in available_vars:\n",
    "            if var in df.columns:\n",
    "                # Calcular pendiente promedio por sujeto\n",
    "                subject_trends = []\n",
    "                for subject in df['subject_id'].unique():\n",
    "                    subject_data = df[df['subject_id'] == subject].sort_values('months_from_baseline')\n",
    "                    if len(subject_data) > 1:\n",
    "                        x = subject_data['months_from_baseline'].values\n",
    "                        y = subject_data[var].values\n",
    "                        # Regresión lineal simple\n",
    "                        slope = np.polyfit(x, y, 1)[0] if not np.isnan(y).all() else 0\n",
    "                        subject_trends.append(slope)\n",
    "                \n",
    "                trends_data[var] = {\n",
    "                    'mean_slope': np.mean(subject_trends) if subject_trends else 0,\n",
    "                    'std_slope': np.std(subject_trends) if subject_trends else 0,\n",
    "                    'progression_subjects': sum(1 for s in subject_trends if s > 0.01) if subject_trends else 0\n",
    "                }\n",
    "    \n",
    "    return trends_data, available_vars\n",
    "\n",
    "# Analizar patrones\n",
    "trends_analysis, temporal_variables = analyze_temporal_patterns(df_temporal)\n",
    "\n",
    "if trends_analysis:\n",
    "    print(\"\\n📈 Tendencias Temporales Detectadas:\")\n",
    "    for var, stats in trends_analysis.items():\n",
    "        print(f\"   {var}:\")\n",
    "        print(f\"      Pendiente promedio: {stats['mean_slope']:.4f}\")\n",
    "        print(f\"      Sujetos con progresión: {stats['progression_subjects']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25555dd0-5e42-4370-9143-8b36c929e1fa",
   "metadata": {},
   "source": [
    "## 3. Modelos de Series Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e0052-585a-40ad-afdd-39bded70534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalRiskModel:\n",
    "    \"\"\"Modelo temporal para predicción de riesgo de Alzheimer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_type='autoregressive'):\n",
    "        self.model_type = model_type\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def create_sequences(self, df, target_col, sequence_length=3, prediction_horizon=1):\n",
    "        \"\"\"Crear secuencias temporales para entrenamiento\"\"\"\n",
    "        \n",
    "        if 'subject_id' not in df.columns:\n",
    "            print(\"⚠️  No hay estructura de sujetos, usando secuencias simples\")\n",
    "            # Crear secuencias simples\n",
    "            X, y = [], []\n",
    "            data = df[target_col].values\n",
    "            \n",
    "            for i in range(sequence_length, len(data) - prediction_horizon + 1):\n",
    "                X.append(data[i-sequence_length:i])\n",
    "                y.append(data[i:i+prediction_horizon])\n",
    "            \n",
    "            return np.array(X), np.array(y)\n",
    "        \n",
    "        # Crear secuencias por sujeto\n",
    "        X, y = [], []\n",
    "        feature_cols = [col for col in df.columns \n",
    "                       if col not in ['subject_id', 'visit_number', 'months_from_baseline']]\n",
    "        \n",
    "        for subject in df['subject_id'].unique():\n",
    "            subject_data = df[df['subject_id'] == subject].sort_values('months_from_baseline')\n",
    "            \n",
    "            if len(subject_data) >= sequence_length + prediction_horizon:\n",
    "                # Crear secuencias para este sujeto\n",
    "                subject_features = subject_data[feature_cols].values\n",
    "                subject_target = subject_data[target_col].values\n",
    "                \n",
    "                for i in range(sequence_length, len(subject_data) - prediction_horizon + 1):\n",
    "                    # Características de ventana temporal\n",
    "                    X_seq = subject_features[i-sequence_length:i].flatten()\n",
    "                    y_seq = subject_target[i:i+prediction_horizon]\n",
    "                    \n",
    "                    if not np.isnan(X_seq).any() and not np.isnan(y_seq).any():\n",
    "                        X.append(X_seq)\n",
    "                        y.append(y_seq.mean())  # Predicción promedio del horizonte\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def fit_autoregressive_model(self, X, y, model_name=\"AR_Model\"):\n",
    "        \"\"\"Entrena modelo autoregresivo\"\"\"\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"temporal_{model_name}\"):\n",
    "            # Escalado\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # Modelo Random Forest para capturar no-linealidades temporales\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Entrenamiento\n",
    "            model.fit(X_scaled, y)\n",
    "            \n",
    "            # Almacenar\n",
    "            self.models[model_name] = model\n",
    "            self.scalers[model_name] = scaler\n",
    "            \n",
    "            # Feature importance si está disponible\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                self.feature_importance[model_name] = model.feature_importances_\n",
    "            \n",
    "            # Métricas básicas en conjunto de entrenamiento\n",
    "            y_pred = model.predict(X_scaled)\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            mae = mean_absolute_error(y, y_pred)\n",
    "            r2 = r2_score(y, y_pred)\n",
    "            \n",
    "            # Log MLflow\n",
    "            mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "            mlflow.log_param(\"n_estimators\", 100)\n",
    "            mlflow.log_param(\"sequence_length\", X.shape[1])\n",
    "            mlflow.log_metric(\"train_mse\", mse)\n",
    "            mlflow.log_metric(\"train_mae\", mae)\n",
    "            mlflow.log_metric(\"train_r2\", r2)\n",
    "            \n",
    "            mlflow.sklearn.log_model(model, \"temporal_model\")\n",
    "            \n",
    "            print(f\"✅ Modelo {model_name} entrenado:\")\n",
    "            print(f\"   MSE: {mse:.4f}\")\n",
    "            print(f\"   MAE: {mae:.4f}\")\n",
    "            print(f\"   R²: {r2:.4f}\")\n",
    "            \n",
    "            return model\n",
    "    \n",
    "    def fit_trend_model(self, df, target_col, model_name=\"Trend_Model\"):\n",
    "        \"\"\"Modelo de tendencias temporales\"\"\"\n",
    "        \n",
    "        if 'months_from_baseline' not in df.columns:\n",
    "            print(\"⚠️  No hay información temporal para modelo de tendencias\")\n",
    "            return None\n",
    "            \n",
    "        with mlflow.start_run(run_name=f\"temporal_{model_name}\"):\n",
    "            # Preparar features temporales\n",
    "            features = ['months_from_baseline']\n",
    "            \n",
    "            # Agregar features adicionales si están disponibles\n",
    "            additional_features = ['age_standardized', 'APOE_e4_present', 'biomarker_risk_score']\n",
    "            for feat in additional_features:\n",
    "                if feat in df.columns:\n",
    "                    features.append(feat)\n",
    "            \n",
    "            X = df[features].fillna(df[features].mean())\n",
    "            y = df[target_col].fillna(df[target_col].mean())\n",
    "            \n",
    "            # Escalado\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # Modelo Ridge para tendencias\n",
    "            model = Ridge(alpha=1.0, random_state=42)\n",
    "            model.fit(X_scaled, y)\n",
    "            \n",
    "            # Almacenar\n",
    "            self.models[model_name] = model\n",
    "            self.scalers[model_name] = scaler\n",
    "            \n",
    "            # Métricas\n",
    "            y_pred = model.predict(X_scaled)\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            mae = mean_absolute_error(y, y_pred)\n",
    "            r2 = r2_score(y, y_pred)\n",
    "            \n",
    "            # Log MLflow\n",
    "            mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "            mlflow.log_param(\"alpha\", 1.0)\n",
    "            mlflow.log_param(\"features\", features)\n",
    "            mlflow.log_metric(\"train_mse\", mse)\n",
    "            mlflow.log_metric(\"train_mae\", mae)\n",
    "            mlflow.log_metric(\"train_r2\", r2)\n",
    "            \n",
    "            mlflow.sklearn.log_model(model, \"trend_model\")\n",
    "            \n",
    "            print(f\"✅ Modelo {model_name} entrenado:\")\n",
    "            print(f\"   Features utilizadas: {len(features)}\")\n",
    "            print(f\"   MSE: {mse:.4f}\")\n",
    "            print(f\"   R²: {r2:.4f}\")\n",
    "            \n",
    "            return model\n",
    "\n",
    "# Inicializar modelo temporal\n",
    "temporal_model = TemporalRiskModel()\n",
    "\n",
    "print(\"🤖 Desarrollando Modelos Temporales...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab97f5-ea05-4859-afdc-125699a9fd8b",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento de Modelos Autoregresivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159acd2-c950-40d9-a9e6-cc86eb253920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo autoregresivo para composite_risk_score\n",
    "if 'composite_risk_score' in df_temporal.columns:\n",
    "    print(\"\\n🔄 Entrenando Modelo Autoregresivo...\")\n",
    "    \n",
    "    # Crear secuencias temporales\n",
    "    X_seq, y_seq = temporal_model.create_sequences(\n",
    "        df_temporal, \n",
    "        'composite_risk_score', \n",
    "        sequence_length=3,\n",
    "        prediction_horizon=1\n",
    "    )\n",
    "    \n",
    "    if len(X_seq) > 0:\n",
    "        print(f\"   Secuencias creadas: {X_seq.shape}\")\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        ar_model = temporal_model.fit_autoregressive_model(\n",
    "            X_seq, y_seq, \"Autoregressive_Risk\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"⚠️  No se pudieron crear suficientes secuencias temporales\")\n",
    "        \n",
    "        # Modelo simplificado con datos disponibles\n",
    "        target_col = 'composite_risk_score'\n",
    "        available_features = [col for col in df_temporal.columns \n",
    "                            if col != target_col and df_temporal[col].dtype in ['int64', 'float64']]\n",
    "        \n",
    "        if available_features:\n",
    "            X_simple = df_temporal[available_features].fillna(df_temporal[available_features].mean())\n",
    "            y_simple = df_temporal[target_col].fillna(df_temporal[target_col].mean())\n",
    "            \n",
    "            ar_model = temporal_model.fit_autoregressive_model(\n",
    "                X_simple.values, y_simple.values, \"Simple_Risk_Model\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3069a5-c5ff-4e2f-b51e-f1a5e88f092a",
   "metadata": {},
   "source": [
    "## 5. Modelos de Tendencias Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765be10-63f1-414d-8f63-e9579a04004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de tendencias\n",
    "print(\"\\n📈 Entrenando Modelo de Tendencias...\")\n",
    "\n",
    "if 'composite_risk_score' in df_temporal.columns:\n",
    "    trend_model = temporal_model.fit_trend_model(\n",
    "        df_temporal, 'composite_risk_score', \"Risk_Trend\"\n",
    "    )\n",
    "\n",
    "# Modelo específico para biomarcadores si están disponibles\n",
    "biomarker_cols = ['biomarker_risk_score', 'ABETA42', 'tau_pathology_score']\n",
    "available_biomarkers = [col for col in biomarker_cols if col in df_temporal.columns]\n",
    "\n",
    "for biomarker in available_biomarkers:\n",
    "    print(f\"\\n🧬 Modelo de tendencias para {biomarker}...\")\n",
    "    temporal_model.fit_trend_model(\n",
    "        df_temporal, biomarker, f\"Trend_{biomarker}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a351e97-317f-4f14-98df-b41ef4ce9391",
   "metadata": {},
   "source": [
    "## 6. Análisis de Supervivencia Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c09e9-d536-45e1-9d8b-a5e96d68c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalRiskModel:\n",
    "    \"\"\"Modelo de supervivencia para progresión del riesgo\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def create_survival_data(self, df, risk_threshold=0.6):\n",
    "        \"\"\"Crear datos para análisis de supervivencia\"\"\"\n",
    "        \n",
    "        if 'subject_id' not in df.columns or 'months_from_baseline' not in df.columns:\n",
    "            print(\"⚠️  Datos insuficientes para análisis de supervivencia\")\n",
    "            return None, None, None\n",
    "        \n",
    "        survival_data = []\n",
    "        \n",
    "        for subject in df['subject_id'].unique():\n",
    "            subject_data = df[df['subject_id'] == subject].sort_values('months_from_baseline')\n",
    "            \n",
    "            # Determinar tiempo hasta evento (riesgo alto)\n",
    "            high_risk_visits = subject_data[subject_data['composite_risk_score'] >= risk_threshold]\n",
    "            \n",
    "            if len(high_risk_visits) > 0:\n",
    "                # Evento ocurrió\n",
    "                time_to_event = high_risk_visits.iloc[0]['months_from_baseline']\n",
    "                event = 1\n",
    "            else:\n",
    "                # Censurado\n",
    "                time_to_event = subject_data['months_from_baseline'].max()\n",
    "                event = 0\n",
    "            \n",
    "            # Features del baseline\n",
    "            baseline_features = subject_data.iloc[0]\n",
    "            \n",
    "            survival_row = {\n",
    "                'subject_id': subject,\n",
    "                'time_to_event': time_to_event,\n",
    "                'event': event,\n",
    "                'baseline_risk': baseline_features.get('composite_risk_score', 0),\n",
    "                'age': baseline_features.get('age_standardized', 70),\n",
    "                'apoe_status': baseline_features.get('APOE_e4_present', 0),\n",
    "                'baseline_biomarker': baseline_features.get('biomarker_risk_score', 0)\n",
    "            }\n",
    "            \n",
    "            survival_data.append(survival_row)\n",
    "        \n",
    "        survival_df = pd.DataFrame(survival_data)\n",
    "        \n",
    "        # Preparar features\n",
    "        feature_cols = ['baseline_risk', 'age', 'apoe_status', 'baseline_biomarker']\n",
    "        X = survival_df[feature_cols].fillna(survival_df[feature_cols].mean())\n",
    "        T = survival_df['time_to_event']\n",
    "        E = survival_df['event']\n",
    "        \n",
    "        return X, T, E\n",
    "    \n",
    "    def fit_cox_approximation(self, X, T, E, model_name=\"Cox_Approximation\"):\n",
    "        \"\"\"Aproximación del modelo de Cox usando regresión\"\"\"\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"survival_{model_name}\"):\n",
    "            # Como aproximación, usar tiempo ponderado por evento\n",
    "            # Los eventos tienen más peso\n",
    "            weights = np.where(E == 1, 2.0, 1.0)\n",
    "            \n",
    "            # Modelo Ridge ponderado\n",
    "            from sklearn.linear_model import Ridge\n",
    "            model = Ridge(alpha=0.1, random_state=42)\n",
    "            \n",
    "            # Ajustar con pesos\n",
    "            sample_weight = weights\n",
    "            model.fit(X, T, sample_weight=sample_weight)\n",
    "            \n",
    "            self.model = model\n",
    "            \n",
    "            # Métricas básicas\n",
    "            T_pred = model.predict(X)\n",
    "            mse = mean_squared_error(T, T_pred, sample_weight=sample_weight)\n",
    "            \n",
    "            # Log MLflow\n",
    "            mlflow.log_param(\"model_type\", \"Weighted_Ridge_Survival\")\n",
    "            mlflow.log_param(\"alpha\", 0.1)\n",
    "            mlflow.log_param(\"events_observed\", E.sum())\n",
    "            mlflow.log_param(\"total_subjects\", len(E))\n",
    "            mlflow.log_metric(\"weighted_mse\", mse)\n",
    "            mlflow.log_metric(\"event_rate\", E.mean())\n",
    "            \n",
    "            mlflow.sklearn.log_model(model, \"survival_model\")\n",
    "            \n",
    "            print(f\"✅ Modelo de supervivencia entrenado:\")\n",
    "            print(f\"   Eventos observados: {E.sum()}/{len(E)} ({E.mean():.2%})\")\n",
    "            print(f\"   MSE ponderado: {mse:.4f}\")\n",
    "            \n",
    "            return model\n",
    "\n",
    "# Análisis de supervivencia\n",
    "print(\"\\n⏱️  Desarrollando Modelo de Supervivencia...\")\n",
    "\n",
    "survival_model = SurvivalRiskModel()\n",
    "X_surv, T_surv, E_surv = survival_model.create_survival_data(df_temporal)\n",
    "\n",
    "if X_surv is not None:\n",
    "    print(f\"   Sujetos para análisis: {len(X_surv)}\")\n",
    "    cox_model = survival_model.fit_cox_approximation(X_surv, T_surv, E_surv)\n",
    "else:\n",
    "    print(\"⚠️  Análisis de supervivencia no disponible con datos actuales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c4f12-5d60-407d-88e7-58069d66be37",
   "metadata": {},
   "source": [
    "## 7. Ensemble Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6bb2bf-383b-48b4-bc3b-9898762da45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalEnsemble:\n",
    "    \"\"\"Ensemble de modelos temporales\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.weights = {}\n",
    "        \n",
    "    def add_model(self, name, model, weight=1.0):\n",
    "        \"\"\"Agregar modelo al ensemble\"\"\"\n",
    "        self.models[name] = model\n",
    "        self.weights[name] = weight\n",
    "        \n",
    "    def predict_ensemble(self, X, scaler_dict=None):\n",
    "        \"\"\"Predicción ensemble ponderada\"\"\"\n",
    "        \n",
    "        if not self.models:\n",
    "            return None\n",
    "            \n",
    "        predictions = []\n",
    "        total_weight = 0\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            try:\n",
    "                # Aplicar escalado si está disponible\n",
    "                if scaler_dict and name in scaler_dict:\n",
    "                    X_scaled = scaler_dict[name].transform(X)\n",
    "                else:\n",
    "                    X_scaled = X\n",
    "                \n",
    "                pred = model.predict(X_scaled)\n",
    "                weight = self.weights[name]\n",
    "                \n",
    "                predictions.append(pred * weight)\n",
    "                total_weight += weight\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Error en modelo {name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if predictions:\n",
    "            ensemble_pred = np.sum(predictions, axis=0) / total_weight\n",
    "            return ensemble_pred\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Crear ensemble temporal\n",
    "print(\"\\n🎯 Creando Ensemble Temporal...\")\n",
    "\n",
    "ensemble = TemporalEnsemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f628cc-766a-41fb-9ec8-e02a665ad66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar modelos disponibles al ensemble\n",
    "for model_name, model in temporal_model.models.items():\n",
    "    ensemble.add_model(model_name, model, weight=1.0)\n",
    "    print(f\"   ✅ Agregado: {model_name}\")\n",
    "\n",
    "if survival_model.model is not None:\n",
    "    ensemble.add_model(\"survival\", survival_model.model, weight=0.5)\n",
    "    print(\"   ✅ Agregado: Survival Model\")\n",
    "\n",
    "print(f\"\\n📊 Ensemble creado con {len(ensemble.models)} modelos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29a8831-119b-43eb-980d-ef2885de7e97",
   "metadata": {},
   "source": [
    "## 8. Validación Temporal Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bfd59b-3054-4dd6-b13b-924da555f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_validation_split(df, test_ratio=0.2):\n",
    "    \"\"\"Split temporal para validación\"\"\"\n",
    "    \n",
    "    if 'months_from_baseline' not in df.columns:\n",
    "        # Split aleatorio si no hay información temporal\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        return train_test_split(df, test_size=test_ratio, random_state=42)\n",
    "    \n",
    "    # Split temporal: últimas visitas para test\n",
    "    time_threshold = df['months_from_baseline'].quantile(1 - test_ratio)\n",
    "    \n",
    "    train_df = df[df['months_from_baseline'] < time_threshold]\n",
    "    test_df = df[df['months_from_baseline'] >= time_threshold]\n",
    "    \n",
    "    print(f\"🔄 Split temporal:\")\n",
    "    print(f\"   Entrenamiento: {len(train_df)} registros (< {time_threshold:.1f} meses)\")\n",
    "    print(f\"   Prueba: {len(test_df)} registros (≥ {time_threshold:.1f} meses)\")\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Realizar split temporal\n",
    "train_temporal, test_temporal = temporal_validation_split(df_temporal)\n",
    "\n",
    "print(\"\\n✅ Validación temporal preparada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584ae36-0a4c-4aea-aaaf-721c95a4aedb",
   "metadata": {},
   "source": [
    "## 9. Guardado de Modelos Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15c23e-9a8d-4528-a1f5-b2bd90738de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Crear directorio para modelos\n",
    "os.makedirs('../models/temporal/', exist_ok=True)\n",
    "\n",
    "print(\"💾 Guardando Modelos Temporales...\")\n",
    "\n",
    "# Guardar modelos individuales\n",
    "for model_name, model in temporal_model.models.items():\n",
    "    model_path = f'../models/temporal/{model_name}.joblib'\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"   ✅ {model_name} guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e674ce0-b7c5-4c5c-95a1-f773080acf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar scalers\n",
    "for scaler_name, scaler in temporal_model.scalers.items():\n",
    "    scaler_path = f'../models/temporal/{scaler_name}_scaler.joblib'\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"   ✅ {scaler_name} scaler guardado\")\n",
    "\n",
    "# Guardar modelo de supervivencia\n",
    "if survival_model.model is not None:\n",
    "    survival_path = '../models/temporal/survival_model.joblib'\n",
    "    joblib.dump(survival_model.model, survival_path)\n",
    "    print(\"   ✅ Survival model guardado\")\n",
    "\n",
    "# Guardar ensemble\n",
    "ensemble_path = '../models/temporal/temporal_ensemble.joblib'\n",
    "joblib.dump(ensemble, ensemble_path)\n",
    "print(\"   ✅ Temporal ensemble guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423bc26-0ebe-4e1f-b036-dc43d9636091",
   "metadata": {},
   "source": [
    "## 10. Resumen del Desarrollo Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ff3c5-8ea8-4b80-89c0-26bf8f9befc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temporal_summary():\n",
    "    \"\"\"Generar resumen del desarrollo de modelos temporales\"\"\"\n",
    "    \n",
    "    summary = {\n",
    "        'models_developed': len(temporal_model.models),\n",
    "        'ensemble_components': len(ensemble.models),\n",
    "        'temporal_features': len(temporal_variables),\n",
    "        'data_points': len(df_temporal),\n",
    "        'unique_subjects': df_temporal['subject_id'].nunique() if 'subject_id' in df_temporal.columns else 'N/A'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📋 RESUMEN DESARROLLO MODELOS TEMPORALES\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"🤖 Modelos desarrollados: {summary['models_developed']}\")\n",
    "    print(f\"🎯 Componentes ensemble: {summary['ensemble_components']}\")\n",
    "    print(f\"📊 Features temporales: {summary['temporal_features']}\")\n",
    "    print(f\"💾 Puntos de datos: {summary['data_points']:,}\")\n",
    "    print(f\"👥 Sujetos únicos: {summary['unique_subjects']}\")\n",
    "    \n",
    "    print(f\"\\n🔧 Modelos específicos desarrollados:\")\n",
    "    for i, model_name in enumerate(temporal_model.models.keys(), 1):\n",
    "        print(f\"   {i}. {model_name}\")\n",
    "    \n",
    "    if survival_model.model is not None:\n",
    "        print(f\"   {len(temporal_model.models) + 1}. Survival Analysis Model\")\n",
    "    \n",
    "    print(f\"\\n📈 Capacidades temporales implementadas:\")\n",
    "    print(f\"   ✅ Predicción autoregresiva\")\n",
    "    print(f\"   ✅ Análisis de tendencias\")\n",
    "    print(f\"   ✅ Ensemble temporal\")\n",
    "    if survival_model.model is not None:\n",
    "        print(f\"   ✅ Análisis de supervivencia\")\n",
    "    \n",
    "    print(f\"\\n🎯 Próximos pasos:\")\n",
    "    print(f\"   - Evaluación exhaustiva en 04e_model_evaluation.ipynb\")\n",
    "    print(f\"   - Optimización de hiperparámetros\")\n",
    "    print(f\"   - Validación cruzada temporal\")\n",
    "    print(f\"   - Análisis de explicabilidad temporal\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Generar resumen final\n",
    "temporal_summary = generate_temporal_summary()\n",
    "\n",
    "print(f\"\\n🏁 Desarrollo de Modelos Temporales COMPLETADO\")\n",
    "print(f\"   📁 Modelos guardados en: ../models/temporal/\")\n",
    "print(f\"   📊 MLflow experiments: temporal_analysis_alzheimer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee44e4-f73c-46ea-a437-af19df4fb0c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc856807-1e1f-4c97-bfb7-446f1b402050",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b82f4-daed-4ee9-ba31-327f05015b99",
   "metadata": {},
   "source": [
    "**Abraham Tartalos**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
