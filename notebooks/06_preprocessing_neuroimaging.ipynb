{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb51756-cb09-444c-9bf9-e83a4816273f",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Neuroim√°genes MRI y PET\n",
    "\n",
    "### Proyecto: Monitorizaci√≥n Multimodal de Alzheimer  \n",
    "#### Subfase 2: Preprocesamiento espec√≠fico para neuroim√°genes (MRI y PET) \n",
    "#### Pipeline de Preprocesamiento de Neuroim√°genes  \n",
    "\n",
    "| **Autor:** Abraham Tartalos  |   \n",
    "**Versi√≥n del Notebook:** 1.0\n",
    "\n",
    "\n",
    "\n",
    "## üìå Descripci√≥n  \n",
    "Pipeline automatizado para el preprocesamiento de im√°genes estructurales (MRI) y funcionales (PET) en estudios de enfermedad de Alzheimer. Incluye:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## üóÇ Estructura de Directorios  \n",
    "```bash\n",
    "data/                           # Datos utilizados en el proyecto  \n",
    "‚îú‚îÄ‚îÄ raw/                        # Datos sin procesar (originales)  \n",
    "‚îÇ   ‚îî‚îÄ‚îÄ adni/                   # Dataset ADNI (o nombre de tu fuente)  \n",
    "‚îÇ       ‚îú‚îÄ‚îÄ images/             # Im√°genes crudas  \n",
    "‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ MRI/            # [DICOM/NIfTI] Im√°genes crudas estructurales  \n",
    "‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ PET/            # [DICOM/NIfTI] Im√°genes crudas funcionales  \n",
    "‚îÇ       ‚îî‚îÄ‚îÄ metadata/           # (Opcional) Archivos cl√≠nicos/par√°metros \n",
    "‚îî‚îÄ‚îÄ processed/\n",
    "    ‚îú‚îÄ‚îÄ mri/          # Im√°genes MRI preprocesadas\n",
    "    ‚îú‚îÄ‚îÄ pet/          # Im√°genes PET preprocesadas  \n",
    "    ‚îú‚îÄ‚îÄ roi/          # M√°scaras de regiones de inter√©s\n",
    "    ‚îî‚îÄ‚îÄ reports/      # Reportes de calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077b9a2-01e3-4979-947e-c60325dcfdc9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05872637-0db1-4205-bcb7-2461e2d60b6a",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a3b5a-2a74-433b-8414-83ee5665367a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importamos bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296ff774-05ed-4e90-86f9-f1ac73565c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "from datetime import datetime\n",
    "from scipy import ndimage\n",
    "from skimage import measure, filters, morphology, segmentation, exposure\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from dask_image.ndfilters import gaussian_filter as dask_gaussian\n",
    "import dask.array as da\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86ae1ee-c3ca-4dba-aefc-5d6ef487a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: Algunas bibliotecas avanzadas no est√°n disponibles. Se usar√°n alternativas b√°sicas.\n"
     ]
    }
   ],
   "source": [
    "# Opcional: bibliotecas m√°s espec√≠ficas para neuroim√°genes\n",
    "try:\n",
    "    import SimpleITK as sitk  # Para registro y filtrado\n",
    "    import ants  # Para registro avanzado y segmentaci√≥n\n",
    "    HAS_ADVANCED_LIBS = True\n",
    "except ImportError:\n",
    "    print(\"Aviso: Algunas bibliotecas avanzadas no est√°n disponibles. Se usar√°n alternativas b√°sicas.\")\n",
    "    HAS_ADVANCED_LIBS = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6980117-29f9-4243-96d6-a882043f0663",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Configuraci√≥n de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b5d02e-1638-4a0c-9290-4083fc9a9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando entorno de trabajo...\n",
      "Directorios de entrada:\n",
      "- MRI: ..\\data\\raw\\adni\\images\\MRI\n",
      "- PET: ..\\data\\raw\\adni\\images\\PET\n",
      "Directorios de salida:\n",
      "- MRI procesados: ..\\data\\processed\\mri\n",
      "- PET procesados: ..\\data\\processed\\pet\n"
     ]
    }
   ],
   "source": [
    "print(\"Configurando entorno de trabajo...\")\n",
    "\n",
    "# Definici√≥n de directorios\n",
    "BASE_DIR = Path(\"../data\")\n",
    "RAW_DIR = BASE_DIR / \"raw\"\n",
    "PROCESSED_DIR = BASE_DIR / \"processed\"\n",
    "MRI_DIR = RAW_DIR / \"adni/images/MRI\"\n",
    "PET_DIR = RAW_DIR / \"adni/images/PET\"\n",
    "OUTPUT_DIR_MRI = PROCESSED_DIR / \"mri\"\n",
    "OUTPUT_DIR_PET = PROCESSED_DIR / \"pet\"\n",
    "\n",
    "REPORT_DIR = Path(\"../reports\")\n",
    "REPORT_PET = REPORT_DIR / \"pet\" \n",
    "REPORT_MRI = REPORT_DIR / \"mri\"\n",
    "\n",
    "# Creaci√≥n de directorios de salida si no existen\n",
    "for dir_path in [OUTPUT_DIR_MRI, OUTPUT_DIR_PET]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(f\"Directorios de entrada:\")\n",
    "print(f\"- MRI: {MRI_DIR}\")\n",
    "print(f\"- PET: {PET_DIR}\")\n",
    "print(f\"Directorios de salida:\")\n",
    "print(f\"- MRI procesados: {OUTPUT_DIR_MRI}\")\n",
    "print(f\"- PET procesados: {OUTPUT_DIR_PET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc932f8-e566-4701-9574-1715097c3d28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Funciones auxiliares para procesamiento de DICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fbd813-718e-4425-99cd-ae9eb8036b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dicom_files(directory, pattern='*.dcm'):\n",
    "    \"\"\"Lista todos los archivos DICOM en un directorio y sus subdirectorios.\"\"\"\n",
    "    directory = Path(directory)\n",
    "    all_files = list(directory.glob(f\"**/{pattern}\"))\n",
    "    return all_files\n",
    "\n",
    "def read_dicom_series(dicom_files):\n",
    "    \"\"\"Lee una serie de archivos DICOM y los convierte a un array 3D.\"\"\"\n",
    "    # Leer todos los archivos DICOM\n",
    "    dicoms = [pydicom.dcmread(str(f)) for f in dicom_files]\n",
    "    \n",
    "    # Ordenar por posici√≥n (SliceLocation o InstanceNumber)\n",
    "    if hasattr(dicoms[0], 'SliceLocation'):\n",
    "        dicoms.sort(key=lambda x: x.SliceLocation)\n",
    "    else:\n",
    "        dicoms.sort(key=lambda x: x.InstanceNumber)\n",
    "    \n",
    "    # Extraer pixeles y stack para formar un volumen 3D\n",
    "    volume = np.stack([d.pixel_array for d in dicoms])\n",
    "    \n",
    "    # Normalizar a valores entre 0 y 1\n",
    "    volume = volume.astype(np.float32)\n",
    "    volume = (volume - volume.min()) / (volume.max() - volume.min())\n",
    "    \n",
    "    return volume, dicoms[0]\n",
    "\n",
    "def convert_dicom_to_nifti(dicom_files, output_path):\n",
    "    \"\"\"Convierte archivos DICOM a formato NIfTI.\"\"\"\n",
    "    if HAS_ADVANCED_LIBS:\n",
    "        # Usar SimpleITK para conversi√≥n m√°s robusta\n",
    "        reader = sitk.ImageSeriesReader()\n",
    "        reader.SetFileNames([str(f) for f in dicom_files])\n",
    "        image = reader.Execute()\n",
    "        sitk.WriteImage(image, str(output_path))\n",
    "    else:\n",
    "        # Alternativa b√°sica usando solo numpy y nibabel\n",
    "        volume, first_dicom = read_dicom_series(dicom_files)\n",
    "        \n",
    "        # Crear affine transform b√°sica (esto deber√≠a mejorarse en producci√≥n)\n",
    "        pixel_spacing = first_dicom.PixelSpacing\n",
    "        slice_thickness = first_dicom.SliceThickness if hasattr(first_dicom, 'SliceThickness') else 1.0\n",
    "        \n",
    "        affine = np.eye(4)\n",
    "        affine[0, 0] = pixel_spacing[0]\n",
    "        affine[1, 1] = pixel_spacing[1]\n",
    "        affine[2, 2] = slice_thickness\n",
    "        \n",
    "        # Guardar como NIfTI\n",
    "        nifti_img = nib.Nifti1Image(volume, affine)\n",
    "        nib.save(nifti_img, output_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def preprocess_brain_volume(volume):\n",
    "    \"\"\"Preprocesamiento b√°sico para vol√∫menes cerebrales.\"\"\"\n",
    "    # 1. Normalizaci√≥n de intensidad\n",
    "    volume = exposure.rescale_intensity(volume)\n",
    "    \n",
    "    # 2. Eliminaci√≥n de ruido con filtro gaussiano\n",
    "    volume = ndimage.gaussian_filter(volume, sigma=1.0)\n",
    "    \n",
    "    # 3. Umbralizaci√≥n para separar cerebro del fondo (m√©todo simple)\n",
    "    threshold = filters.threshold_otsu(volume)\n",
    "    mask = volume > threshold\n",
    "    \n",
    "    # 4. Operaciones morfol√≥gicas para limpiar la m√°scara\n",
    "    mask = morphology.binary_opening(mask, morphology.ball(2))\n",
    "    mask = morphology.binary_closing(mask, morphology.ball(2))\n",
    "    \n",
    "    # 5. Etiquetado de componentes y selecci√≥n del componente m√°s grande (el cerebro)\n",
    "    labels = measure.label(mask)\n",
    "    regions = measure.regionprops(labels)\n",
    "    if regions:\n",
    "        largest_region = max(regions, key=lambda r: r.area)\n",
    "        mask = labels == largest_region.label\n",
    "    \n",
    "    # 6. Aplicar m√°scara al volumen original\n",
    "    volume_masked = volume.copy()\n",
    "    volume_masked[~mask] = 0\n",
    "    \n",
    "    return volume_masked\n",
    "\n",
    "def register_to_template(image_path, template_path, output_path):\n",
    "    \"\"\"Registra una imagen a una plantilla est√°ndar.\"\"\"\n",
    "    if not HAS_ADVANCED_LIBS:\n",
    "        print(\"Registro espacial requiere ANTs o SimpleITK. Saltando este paso.\")\n",
    "        return image_path\n",
    "    \n",
    "    try:\n",
    "        # Usando ANTs para registro de alta calidad\n",
    "        moving_image = ants.image_read(str(image_path))\n",
    "        fixed_image = ants.image_read(str(template_path))\n",
    "        \n",
    "        # Registro\n",
    "        registration = ants.registration(\n",
    "            fixed=fixed_image,\n",
    "            moving=moving_image,\n",
    "            type_of_transform='SyN'  # SyN para registro no lineal\n",
    "        )\n",
    "        \n",
    "        # Guardar resultado\n",
    "        registered_image = registration['warpedmovout']\n",
    "        ants.image_write(registered_image, str(output_path))\n",
    "        \n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error en registro: {e}\")\n",
    "        return image_path\n",
    "\n",
    "def extract_brain_features(image_path, mask_path=None):\n",
    "    \"\"\"Extrae caracter√≠sticas relevantes de neuroim√°genes para Alzheimer.\"\"\"\n",
    "    # Cargar imagen\n",
    "    if str(image_path).endswith('.nii') or str(image_path).endswith('.nii.gz'):\n",
    "        img = nib.load(str(image_path))\n",
    "        data = img.get_fdata()\n",
    "    else:\n",
    "        # Asumimos que es una serie DICOM\n",
    "        dicom_files = list_dicom_files(image_path) if os.path.isdir(image_path) else [image_path]\n",
    "        data, _ = read_dicom_series(dicom_files)\n",
    "    \n",
    "    # Cargar m√°scara si existe\n",
    "    if mask_path:\n",
    "        mask_img = nib.load(str(mask_path))\n",
    "        mask = mask_img.get_fdata() > 0\n",
    "    else:\n",
    "        # Crear m√°scara simple si no se proporciona\n",
    "        threshold = filters.threshold_otsu(data)\n",
    "        mask = data > threshold\n",
    "    \n",
    "    # Caracter√≠sticas b√°sicas de la imagen\n",
    "    features = {}\n",
    "    \n",
    "    # 1. Estad√≠sticas b√°sicas por regi√≥n\n",
    "    regions = {\n",
    "        'whole_brain': mask,\n",
    "        # Aqu√≠ se a√±adir√≠an m√°scaras para regiones espec√≠ficas como hipocampo, etc.\n",
    "    }\n",
    "    \n",
    "    for region_name, region_mask in regions.items():\n",
    "        region_data = data[region_mask]\n",
    "        if len(region_data) > 0:\n",
    "            features[f\"{region_name}_mean\"] = np.mean(region_data)\n",
    "            features[f\"{region_name}_std\"] = np.std(region_data)\n",
    "            features[f\"{region_name}_median\"] = np.median(region_data)\n",
    "            features[f\"{region_name}_min\"] = np.min(region_data)\n",
    "            features[f\"{region_name}_max\"] = np.max(region_data)\n",
    "            features[f\"{region_name}_volume\"] = np.sum(region_mask)\n",
    "    \n",
    "    # 2. Caracter√≠sticas de textura (GLCM simplificado)\n",
    "    # En producci√≥n usar librer√≠a como radiomics para caracter√≠sticas m√°s avanzadas\n",
    "    from skimage.feature import graycomatrix, graycoprops\n",
    "    \n",
    "    # Tomar una slice central representativa\n",
    "    central_slice = data[:, :, data.shape[2]//2]\n",
    "    central_slice = exposure.rescale_intensity(central_slice, out_range=(0, 255)).astype(np.uint8)\n",
    "    \n",
    "    # Calcular GLCM\n",
    "    try:\n",
    "        glcm = graycomatrix(central_slice, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "        features['texture_contrast'] = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        features['texture_dissimilarity'] = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "        features['texture_homogeneity'] = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        features['texture_energy'] = graycoprops(glcm, 'energy')[0, 0]\n",
    "        features['texture_correlation'] = graycoprops(glcm, 'correlation')[0, 0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error al calcular caracter√≠sticas de textura: {e}\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbe4fe-1287-48de-bcb3-c720f3cb6d00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Preprocesamiento de im√°genes MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac1c093-8ce7-4251-8499-613ed22c3258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando preprocesamiento de im√°genes MRI...\n",
      "Se encontraron 1672 archivos DICOM de MRI.\n",
      "Se encontraron 1195 archivos DICOM de MRI v√°lidos.\n",
      "Se identificaron 4 series MRI distintas.\n",
      "============================================================\n",
      "Total de grupos disponibles: 4\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a21d68964fc46bd9bd592cd3592a328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se extrajeron caracter√≠sticas de 3 im√°genes MRI.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_brain_mean</th>\n",
       "      <th>whole_brain_std</th>\n",
       "      <th>whole_brain_median</th>\n",
       "      <th>whole_brain_min</th>\n",
       "      <th>whole_brain_max</th>\n",
       "      <th>whole_brain_volume</th>\n",
       "      <th>texture_contrast</th>\n",
       "      <th>texture_dissimilarity</th>\n",
       "      <th>texture_homogeneity</th>\n",
       "      <th>texture_energy</th>\n",
       "      <th>texture_correlation</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>modality</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.200336</td>\n",
       "      <td>3863045</td>\n",
       "      <td>61.098023</td>\n",
       "      <td>2.853322</td>\n",
       "      <td>0.747431</td>\n",
       "      <td>0.712147</td>\n",
       "      <td>0.974330</td>\n",
       "      <td>082_S_4224</td>\n",
       "      <td>MRI</td>\n",
       "      <td>..\\data\\processed\\mri\\082_S_4224_processed.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.313711</td>\n",
       "      <td>40304</td>\n",
       "      <td>129.713729</td>\n",
       "      <td>3.718741</td>\n",
       "      <td>0.800853</td>\n",
       "      <td>0.785883</td>\n",
       "      <td>0.931925</td>\n",
       "      <td>082_S_7117</td>\n",
       "      <td>MRI</td>\n",
       "      <td>..\\data\\processed\\mri\\082_S_7117_processed.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.011967</td>\n",
       "      <td>0.291776</td>\n",
       "      <td>4283401</td>\n",
       "      <td>16.729921</td>\n",
       "      <td>1.198351</td>\n",
       "      <td>0.843343</td>\n",
       "      <td>0.800366</td>\n",
       "      <td>0.972220</td>\n",
       "      <td>130_S_5175</td>\n",
       "      <td>MRI</td>\n",
       "      <td>..\\data\\processed\\mri\\130_S_5175_processed.nii.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   whole_brain_mean  whole_brain_std  whole_brain_median  whole_brain_min  \\\n",
       "0          0.020042         0.008530            0.017690         0.009782   \n",
       "1          0.049783         0.020518            0.045161         0.025124   \n",
       "2          0.024835         0.010895            0.021900         0.011967   \n",
       "\n",
       "   whole_brain_max  whole_brain_volume  texture_contrast  \\\n",
       "0         0.200336             3863045         61.098023   \n",
       "1         0.313711               40304        129.713729   \n",
       "2         0.291776             4283401         16.729921   \n",
       "\n",
       "   texture_dissimilarity  texture_homogeneity  texture_energy  \\\n",
       "0               2.853322             0.747431        0.712147   \n",
       "1               3.718741             0.800853        0.785883   \n",
       "2               1.198351             0.843343        0.800366   \n",
       "\n",
       "   texture_correlation  patient_id modality  \\\n",
       "0             0.974330  082_S_4224      MRI   \n",
       "1             0.931925  082_S_7117      MRI   \n",
       "2             0.972220  130_S_5175      MRI   \n",
       "\n",
       "                                           file_path  \n",
       "0  ..\\data\\processed\\mri\\082_S_4224_processed.nii.gz  \n",
       "1  ..\\data\\processed\\mri\\082_S_7117_processed.nii.gz  \n",
       "2  ..\\data\\processed\\mri\\130_S_5175_processed.nii.gz  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nIniciando preprocesamiento de im√°genes MRI...\")\n",
    "\n",
    "# Listar todos los archivos MRI DICOM\n",
    "mri_files = list_dicom_files(MRI_DIR)\n",
    "print(f\"Se encontraron {len(mri_files)} archivos DICOM de MRI.\")\n",
    "\n",
    "\n",
    "# Listar todos los archivos MRI DICOM verdaderos\n",
    "all_candidates = list_dicom_files(MRI_DIR)\n",
    "mri_files = [f for f in all_candidates if f.suffix.lower()=='.dcm' and f.is_file()]\n",
    "print(f\"Se encontraron {len(mri_files)} archivos DICOM de MRI v√°lidos.\")\n",
    "\n",
    "\n",
    "# Agrupar por serie/paciente (simplificado - en producci√≥n hacer m√°s robusto)\n",
    "mri_groups = {}\n",
    "for file_path in mri_files:\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(str(file_path))\n",
    "        # Usar combinaci√≥n de ID de paciente y ID de serie como clave\n",
    "        if hasattr(dicom, 'PatientID') and hasattr(dicom, 'SeriesInstanceUID'):\n",
    "            key = f\"{dicom.PatientID}_{dicom.SeriesInstanceUID}\"\n",
    "            if key not in mri_groups:\n",
    "                mri_groups[key] = []\n",
    "            mri_groups[key].append(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer {file_path}: {e}\")\n",
    "\n",
    "print(f\"Se identificaron {len(mri_groups)} series MRI distintas.\")\n",
    "\n",
    "print(\"==\"*30)\n",
    "# Mostrar el total de grupos disponibles\n",
    "total_grupos = len(mri_groups)\n",
    "print(f\"Total de grupos disponibles: {total_grupos}\")\n",
    "print(\"==\"*30)\n",
    "\n",
    "# Procesar cada serie MRI\n",
    "mri_features = []\n",
    "for i, (group_key, group_files) in enumerate(tqdm(list(mri_groups.items())[:-1])):  # Procesar solo 5 para ejemplo\n",
    "    try:\n",
    "        # 1. Extraer metadatos del primer archivo\n",
    "        dicom = pydicom.dcmread(str(group_files[0]))\n",
    "        patient_id = dicom.PatientID if hasattr(dicom, 'PatientID') else f\"unknown_patient_{i}\"\n",
    "        \n",
    "        # 2. Convertir a NIfTI para procesamiento m√°s f√°cil\n",
    "        nifti_path = OUTPUT_DIR_MRI / f\"{patient_id}_raw.nii.gz\"\n",
    "        convert_dicom_to_nifti(group_files, nifti_path)\n",
    "        \n",
    "        # 3. Preprocesamiento b√°sico\n",
    "        # Cargar volumen\n",
    "        img = nib.load(nifti_path)\n",
    "        data = img.get_fdata()\n",
    "        \n",
    "        # Aplicar preprocesamiento\n",
    "        processed_data = preprocess_brain_volume(data)\n",
    "        \n",
    "        # Guardar resultado\n",
    "        processed_path = OUTPUT_DIR_MRI / f\"{patient_id}_processed.nii.gz\"\n",
    "        processed_img = nib.Nifti1Image(processed_data, img.affine)\n",
    "        nib.save(processed_img, processed_path)\n",
    "        \n",
    "        # 4. Registro a plantilla est√°ndar (opcional, descomentar si necesario)\n",
    "        # template_path = Path(\"./templates/mni152_t1_1mm.nii.gz\")  # Ajustar ruta a tu plantilla\n",
    "        # if template_path.exists():\n",
    "        #     registered_path = OUTPUT_DIR_MRI / f\"{patient_id}_registered.nii.gz\"\n",
    "        #     register_to_template(processed_path, template_path, registered_path)\n",
    "        \n",
    "        # 5. Extracci√≥n de caracter√≠sticas\n",
    "        features = extract_brain_features(processed_path)\n",
    "        features['patient_id'] = patient_id\n",
    "        features['modality'] = 'MRI'\n",
    "        features['file_path'] = str(processed_path)\n",
    "        \n",
    "        mri_features.append(features)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando grupo {group_key}: {e}\")\n",
    "\n",
    "# Convertir a DataFrame\n",
    "if mri_features:\n",
    "    mri_features_df = pd.DataFrame(mri_features)\n",
    "    mri_features_df.to_csv(OUTPUT_DIR_MRI / \"mri_features.csv\", index=False)\n",
    "    print(f\"Se extrajeron caracter√≠sticas de {len(mri_features)} im√°genes MRI.\")\n",
    "    display(mri_features_df.head())\n",
    "else:\n",
    "    print(\"No se pudieron extraer caracter√≠sticas de las im√°genes MRI.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839a68df-b2af-471e-ab46-e5e3889596b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Preprocesamiento de im√°genes PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13fc98a-3298-4e97-9bb0-4b43c1f0d1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando preprocesamiento de im√°genes PET (subconjunto reducido)‚Ä¶\n",
      "Encontradas 360 carpetas de serie PET.\n",
      "Preparadas 293 series PET en total.\n",
      "Procesando subconjunto de 5 series PET para prueba.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2253167d54428e8d79e0cc43df6732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Series PET procesadas:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nIniciando preprocesamiento de im√°genes PET (subconjunto reducido)‚Ä¶\")\n",
    "\n",
    "# 1) Identificar carpetas de serie que contengan .dcm\n",
    "series_dirs = []\n",
    "for root, dirs, files in os.walk(PET_DIR):\n",
    "    if any(f.lower().endswith('.dcm') for f in files):\n",
    "        series_dirs.append(Path(root))\n",
    "print(f\"Encontradas {len(series_dirs)} carpetas de serie PET.\")\n",
    "\n",
    "# 2) Agrupar s√≥lo series completas\n",
    "pet_groups = {}\n",
    "for sd in series_dirs:\n",
    "    dcm_files = [f for f in sd.glob(\"*.dcm\") if f.is_file()]\n",
    "    if len(dcm_files) < 10:\n",
    "        continue\n",
    "    try:\n",
    "        ds = pydicom.dcmread(str(dcm_files[0]), stop_before_pixels=True)\n",
    "        if getattr(ds, 'Modality','').upper() == 'PT':\n",
    "            key = f\"{ds.PatientID}_{ds.SeriesInstanceUID}\"\n",
    "            pet_groups[key] = dcm_files\n",
    "    except Exception:\n",
    "        continue\n",
    "print(f\"Preparadas {len(pet_groups)} series PET en total.\")\n",
    "\n",
    "# 3) Seleccionar un subconjunto de entre 5 y 10 series\n",
    "max_subset = 5  # n√∫mero m√°ximo de series a procesar\n",
    "selected_keys = list(pet_groups.keys())[:max_subset]\n",
    "pet_groups = {k: pet_groups[k] for k in selected_keys}\n",
    "print(f\"Procesando subconjunto de {len(pet_groups)} series PET para prueba.\")\n",
    "\n",
    "# Par√°metros de procesamiento paralelo\\\n",
    "max_workers = 1  # ajusta seg√∫n tu CPU\n",
    "\n",
    "# 4) Funci√≥n de procesamiento de una sola serie (similar al pipeline original)\n",
    "def process_pet_series(args):\n",
    "    key, files = args\n",
    "    start = datetime.now()\n",
    "    try:\n",
    "        ds = pydicom.dcmread(str(files[0]), stop_before_pixels=True)\n",
    "        patient_id = ds.PatientID\n",
    "        # Conversi√≥n DICOM -> NIfTI\n",
    "        raw_nifti = OUTPUT_DIR_PET / f\"{patient_id}_raw.nii.gz\"\n",
    "        if not raw_nifti.exists():\n",
    "            convert_dicom_to_nifti(files, raw_nifti)\n",
    "        # Carga y preprocesamiento\n",
    "        img = nib.load(raw_nifti)\n",
    "        data = img.get_fdata()\n",
    "        # Normalizaci√≥n simplificada y suavizado gaussiano\n",
    "        proc_data = data / np.mean(data[data > 0])\n",
    "        proc_data = ndimage.gaussian_filter(proc_data, sigma=1.0)\n",
    "        processed_nifti = OUTPUT_DIR_PET / f\"{patient_id}_processed.nii.gz\"\n",
    "        nib.save(nib.Nifti1Image(proc_data, img.affine), processed_nifti)\n",
    "        # Extracci√≥n de features\n",
    "        feats = extract_brain_features(processed_nifti)\n",
    "        feats.update({'patient_id': patient_id,\n",
    "                      'modality': 'PET',\n",
    "                      'file_path': str(processed_nifti)})\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        print(f\"Serie {key} procesada en {elapsed:.1f} seg.\")\n",
    "        return feats\n",
    "    except Exception as e:\n",
    "        elapsed = (datetime.now() - start).total_seconds()\n",
    "        print(f\"Error en serie {key} tras {elapsed:.1f} seg: {e}\")\n",
    "        return None\n",
    "\n",
    "# 5) Procesamiento paralelo del subconjunto\n",
    "pet_features = []\n",
    "with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = {executor.submit(process_pet_series, item): item for item in pet_groups.items()}\n",
    "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Series PET procesadas\"):\n",
    "        res = fut.result()\n",
    "        if res:\n",
    "            pet_features.append(res)\n",
    "\n",
    "# 6) Guardar resultados\n",
    "if pet_features:\n",
    "    pet_df = pd.DataFrame(pet_features)\n",
    "    pet_df.to_csv(OUTPUT_DIR_PET / \"pet_features_subset.csv\", index=False)\n",
    "    print(f\"Se extrajeron caracter√≠sticas de {len(pet_features)} series PET.\")\n",
    "    display(pet_df.head())\n",
    "else:\n",
    "    print(\"No se pudieron extraer caracter√≠sticas del subconjunto PET.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b44f2-1ce3-4f51-906f-3c83ae337143",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Visualizaci√≥n de resultados del preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6e7003-d7e3-4fe9-a331-46884af297cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generando visualizaciones de control de calidad...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerando visualizaciones de control de calidad...\")\n",
    "\n",
    "def plot_preprocessing_results(original_path, processed_path, title):\n",
    "    \"\"\"Muestra comparaci√≥n de imagen original y procesada.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Cargar im√°genes\n",
    "    original_img = nib.load(original_path)\n",
    "    original_data = original_img.get_fdata()\n",
    "    \n",
    "    processed_img = nib.load(processed_path)\n",
    "    processed_data = processed_img.get_fdata()\n",
    "    \n",
    "    # Mostrar slices centrales\n",
    "    slice_idx = original_data.shape[2] // 2\n",
    "    \n",
    "    axes[0].imshow(original_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(processed_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[1].set_title('Procesada')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Visualizar un ejemplo de MRI procesado (si existe)\n",
    "mri_examples = list(OUTPUT_DIR_MRI.glob('*_raw.nii.gz'))\n",
    "if mri_examples:\n",
    "    original_path = mri_examples[0]\n",
    "    processed_path = original_path.parent / original_path.name.replace('_raw', '_processed')\n",
    "    if processed_path.exists():\n",
    "        fig = plot_preprocessing_results(original_path, processed_path, 'Ejemplo de Preprocesamiento MRI')\n",
    "        plt.savefig(REPORT_MRI / 'mri_preprocessing_example.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "# Visualizar un ejemplo de PET procesado (si existe)\n",
    "pet_examples = list(OUTPUT_DIR_PET.glob('*_raw.nii.gz'))\n",
    "if pet_examples:\n",
    "    original_path = pet_examples[0]\n",
    "    processed_path = original_path.parent / original_path.name.replace('_raw', '_processed')\n",
    "    if processed_path.exists():\n",
    "        fig = plot_preprocessing_results(original_path, processed_path, 'Ejemplo de Preprocesamiento PET')\n",
    "        plt.savefig(REPORT_PET / 'pet_preprocessing_example.png')\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb460b22-8a4e-4eb2-8d5e-357f1c310d39",
   "metadata": {},
   "source": [
    "## 6. Integraci√≥n de caracter√≠sticas MRI y PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8c9f84-36f2-4d13-8bf2-b7ec6e9b6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integrando caracter√≠sticas de MRI y PET...\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIntegrando caracter√≠sticas de MRI y PET...\")\n",
    "\n",
    "# Combinar caracter√≠sticas si existen ambos tipos\n",
    "if 'mri_features_df' in locals() and 'pet_features_df' in locals():\n",
    "    print(\"1\")\n",
    "    # Concatenar\n",
    "    all_features_df = pd.concat([mri_features_df, pet_features_df], ignore_index=True)\n",
    "    \n",
    "    # Guardar\n",
    "    all_features_df.to_csv(PROCESSED_DIR / \"neuroimaging_features.csv\", index=False)\n",
    "    print(f\"Se guardaron {len(all_features_df)} registros de caracter√≠sticas de neuroim√°genes.\")\n",
    "    \n",
    "    # Pivot table para ver pacientes con ambas modalidades\n",
    "    modality_pivot = all_features_df.pivot_table(\n",
    "        index='patient_id', \n",
    "        columns='modality', \n",
    "        values='file_path', \n",
    "        aggfunc='count', \n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    print(\"\\nDistribuci√≥n de modalidades por paciente:\")\n",
    "    display(modality_pivot.head())\n",
    "    \n",
    "    # Estad√≠sticas de caracter√≠sticas por modalidad\n",
    "    print(\"\\nEstad√≠sticas de caracter√≠sticas por modalidad:\")\n",
    "    numeric_features = all_features_df.select_dtypes(include=[np.number])\n",
    "    stats_by_modality = all_features_df.groupby('modality')[numeric_features.columns].mean()\n",
    "    display(stats_by_modality)\n",
    "else:\n",
    "    print(\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fedd9-fe0e-46ea-a730-2987212e9a2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Resumen y recomendaciones para siguiente fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6af6b1dd-8290-424e-a03e-9d5a25d74c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESUMEN DE PREPROCESAMIENTO DE NEUROIM√ÅGENES\n",
      "================================================================================\n",
      "\n",
      "Se ha completado el preprocesamiento b√°sico de neuroim√°genes MRI y PET:\n",
      "\n",
      "1. Conversi√≥n de formato DICOM a NIfTI para facilitar an√°lisis\n",
      "2. Preprocesamiento espec√≠fico por modalidad:\n",
      "   - MRI: Normalizaci√≥n, reducci√≥n de ruido, segmentaci√≥n cerebral\n",
      "   - PET: Normalizaci√≥n espec√≠fica (pseudo-SUV), suavizado\n",
      "3. Extracci√≥n de caracter√≠sticas b√°sicas:\n",
      "   - Estad√≠sticas por regi√≥n cerebral\n",
      "   - Caracter√≠sticas de textura\n",
      "4. Integraci√≥n de caracter√≠sticas de ambas modalidades\n",
      "\n",
      "Limitaciones actuales:\n",
      "- No se ha implementado registro completo a atlas est√°ndar MNI152\n",
      "- Segmentaci√≥n b√°sica de regiones cerebrales (sin atlas espec√≠fico de regiones)\n",
      "- Caracter√≠sticas de textura simplificadas\n",
      "\n",
      "Recomendaciones para siguiente fase (Feature Engineering):\n",
      "1. Implementar segmentaci√≥n avanzada de regiones espec√≠ficas para Alzheimer:\n",
      "   - Hipocampo\n",
      "   - Corteza entorrinal\n",
      "   - Volumen ventricular\n",
      "   - Grosor cortical\n",
      "2. Calcular biomarcadores espec√≠ficos:\n",
      "   - MRI: Volumetr√≠a de regiones, √≠ndices de atrofia\n",
      "   - PET: SUVr en regiones espec√≠ficas comparadas con cerebelo\n",
      "3. Incorporar atlas cerebrales para normalizaci√≥n espacial\n",
      "4. Desarrollar caracter√≠sticas espec√≠ficas para detecci√≥n temprana de Alzheimer\n",
      "\n",
      "\n",
      "Preprocesamiento de neuroim√°genes completado!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE PREPROCESAMIENTO DE NEUROIM√ÅGENES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "Se ha completado el preprocesamiento b√°sico de neuroim√°genes MRI y PET:\n",
    "\n",
    "1. Conversi√≥n de formato DICOM a NIfTI para facilitar an√°lisis\n",
    "2. Preprocesamiento espec√≠fico por modalidad:\n",
    "   - MRI: Normalizaci√≥n, reducci√≥n de ruido, segmentaci√≥n cerebral\n",
    "   - PET: Normalizaci√≥n espec√≠fica (pseudo-SUV), suavizado\n",
    "3. Extracci√≥n de caracter√≠sticas b√°sicas:\n",
    "   - Estad√≠sticas por regi√≥n cerebral\n",
    "   - Caracter√≠sticas de textura\n",
    "4. Integraci√≥n de caracter√≠sticas de ambas modalidades\n",
    "\n",
    "Limitaciones actuales:\n",
    "- No se ha implementado registro completo a atlas est√°ndar MNI152\n",
    "- Segmentaci√≥n b√°sica de regiones cerebrales (sin atlas espec√≠fico de regiones)\n",
    "- Caracter√≠sticas de textura simplificadas\n",
    "\n",
    "Recomendaciones para siguiente fase (Feature Engineering):\n",
    "1. Implementar segmentaci√≥n avanzada de regiones espec√≠ficas para Alzheimer:\n",
    "   - Hipocampo\n",
    "   - Corteza entorrinal\n",
    "   - Volumen ventricular\n",
    "   - Grosor cortical\n",
    "2. Calcular biomarcadores espec√≠ficos:\n",
    "   - MRI: Volumetr√≠a de regiones, √≠ndices de atrofia\n",
    "   - PET: SUVr en regiones espec√≠ficas comparadas con cerebelo\n",
    "3. Incorporar atlas cerebrales para normalizaci√≥n espacial\n",
    "4. Desarrollar caracter√≠sticas espec√≠ficas para detecci√≥n temprana de Alzheimer\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nPreprocesamiento de neuroim√°genes completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f216d5e-16a3-426f-9488-17ce122f52ec",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec469a67-14b3-48a1-bcc1-ea06da8eaeef",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16b837-7cf4-4dd7-9f68-ba269b57245b",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a2623-99ce-411f-9e51-77cbb6ac7ce3",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da6681-8c68-446b-9628-b8d06cd14e2a",
   "metadata": {},
   "source": [
    "__Abraham Tartalos__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Alzheimer)",
   "language": "python",
   "name": "alzheimer-env-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
